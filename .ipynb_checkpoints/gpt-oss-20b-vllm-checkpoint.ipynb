{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SageMaker VLLM endpoint example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Define some variables\n",
    "\n",
    "The byoc will build and store a vllm endpoint docker image in you ECR private repo (for example `sagemaker_endpoint/vllm`), you need to define the following variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"openai/gpt-oss-20b\"\n",
    "INSTANCE_TYPE = \"ml.g5.xlarge\"\n",
    "VLLM_VERSION = \"v0.10.2\"\n",
    "REPO_NAMESPACE = \"sagemaker_endpoint/vllm\"\n",
    "ACCOUNT = !aws sts get-caller-identity --query Account --output text\n",
    "REGION = !aws configure get region\n",
    "ACCOUNT = ACCOUNT[0]\n",
    "REGION = REGION[0]\n",
    "\n",
    "VLLM_REPO = \"vllm/vllm-openai\"\n",
    "CONTAINER = f\"{ACCOUNT}.dkr.ecr.{REGION}.amazonaws.com/{REPO_NAMESPACE}:{VLLM_VERSION}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the container\n",
    "\n",
    "Endpoint starting codes are in `app/`. The script will build and push to ecr. \n",
    "\n",
    "**The docker only need to be built once**, and after that, when deploying other endpoints, the same docker image can be shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runging: VLLM_REPO=vllm/vllm-openai VLLM_VERSION=v0.10.2 REPO_NAMESPACE=sagemaker_endpoint/vllm ACCOUNT=340636688520 REGION=us-west-2 bash ./build_and_push.sh \n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "340636688520.dkr.ecr.us-west-2.amazonaws.com/sagemaker_endpoint/vllm:v0.10.2\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (1/2)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (1/2)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (1/2)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (2/2)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.8s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.1s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.2s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   0.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.4s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   0.7s\n",
      "\u001b[2m => => # Collecting s5cmd                                                      \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.5s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   0.9s\n",
      "\u001b[2m => => # 0 kB)                                                                 \n",
      "\u001b[0m\u001b[2m => => # Requirement already satisfied: requests in /usr/local/lib/python3.12/d\n",
      "\u001b[0m\u001b[2m => => # ist-packages (2.32.5)                                                 \n",
      "\u001b[0m\u001b[2m => => # Requirement already satisfied: boto3 in /usr/local/lib/python3.12/dist\n",
      "\u001b[0m\u001b[2m => => # -packages (1.40.30)                                                   \n",
      "\u001b[0m\u001b[2m => => # Collecting sagemaker>=2.145.0 (from sagemaker-ssh-helper)             \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.6s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   1.0s\n",
      "\u001b[2m => => # Collecting docker (from sagemaker>=2.145.0->sagemaker-ssh-helper)     \n",
      "\u001b[0m\u001b[2m => => #   Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)         \n",
      "\u001b[0m\u001b[2m => => # Requirement already satisfied: fastapi in /usr/local/lib/python3.12/di\n",
      "\u001b[0m\u001b[2m => => # st-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (0.116.1) \n",
      "\u001b[0m\u001b[2m => => # Collecting google-pasta (from sagemaker>=2.145.0->sagemaker-ssh-helper\n",
      "\u001b[0m\u001b[2m => => # )                                                                     \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.8s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   1.2s\n",
      "\u001b[2m => => # Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /usr/\n",
      "\u001b[0m\u001b[2m => => # lib/python3/dist-packages (from sagemaker>=2.145.0->sagemaker-ssh-help\n",
      "\u001b[0m\u001b[2m => => # er) (4.6.4)                                                           \n",
      "\u001b[0m\u001b[2m => => # Requirement already satisfied: jsonschema in /usr/local/lib/python3.12\n",
      "\u001b[0m\u001b[2m => => # /dist-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (4.25.1\n",
      "\u001b[0m\u001b[2m => => # )                                                                     \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.8s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   1.2s\n",
      "\u001b[2m => => # er) (4.6.4)                                                           \n",
      "\u001b[0m\u001b[2m => => # Requirement already satisfied: jsonschema in /usr/local/lib/python3.12\n",
      "\u001b[0m\u001b[2m => => # /dist-packages (from sagemaker>=2.145.0->sagemaker-ssh-helper) (4.25.1\n",
      "\u001b[0m\u001b[2m => => # )                                                                     \n",
      "\u001b[0m\u001b[2m => => # Collecting numpy==1.26.4 (from sagemaker>=2.145.0->sagemaker-ssh-helpe\n",
      "\u001b[0m\u001b[2m => => # r)                                                                    \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.0s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   1.4s\n",
      "\u001b[2m => => # elper)                                                                \n",
      "\u001b[0m\u001b[2m => => #   Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)      \n",
      "\u001b[0m\u001b[2m => => # Collecting packaging<25,>=23.0 (from sagemaker>=2.145.0->sagemaker-ssh\n",
      "\u001b[0m\u001b[2m => => # -helper)                                                              \n",
      "\u001b[0m\u001b[2m => => #   Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)       \n",
      "\u001b[0m\u001b[2m => => # Collecting pandas (from sagemaker>=2.145.0->sagemaker-ssh-helper)     \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.2s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   1.6s\n",
      "\u001b[2m => => # 2014_x86_64.whl.metadata (91 kB)                                      \n",
      "\u001b[0m\u001b[2m => => # Collecting pathos (from sagemaker>=2.145.0->sagemaker-ssh-helper)     \n",
      "\u001b[0m\u001b[2m => => #   Downloading pathos-0.3.4-py3-none-any.whl.metadata (11 kB)          \n",
      "\u001b[0m\u001b[2m => => # Collecting platformdirs (from sagemaker>=2.145.0->sagemaker-ssh-helper\n",
      "\u001b[0m\u001b[2m => => # )                                                                     \n",
      "\u001b[0m\u001b[2m => => #   Downloading platformdirs-4.4.0-py3-none-any.whl.metadata (12 kB)    \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.3s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   1.7s\n",
      "\u001b[2m => => #   Downloading pathos-0.3.4-py3-none-any.whl.metadata (11 kB)          \n",
      "\u001b[0m\u001b[2m => => # Collecting platformdirs (from sagemaker>=2.145.0->sagemaker-ssh-helper\n",
      "\u001b[0m\u001b[2m => => # )                                                                     \n",
      "\u001b[0m\u001b[2m => => #   Downloading platformdirs-4.4.0-py3-none-any.whl.metadata (12 kB)    \n",
      "\u001b[0m\u001b[2m => => # Collecting protobuf<6.32,>=3.12 (from sagemaker>=2.145.0->sagemaker-ss\n",
      "\u001b[0m\u001b[2m => => # h-helper)                                                             \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.4s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   1.8s\n",
      "\u001b[2m => => # ker-ssh-helper)                                                       \n",
      "\u001b[0m\u001b[2m => => #   Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl.metadata \n",
      "\u001b[0m\u001b[2m => => # (943 bytes)                                                           \n",
      "\u001b[0m\u001b[2m => => # Collecting tblib<4,>=1.7.0 (from sagemaker>=2.145.0->sagemaker-ssh-hel\n",
      "\u001b[0m\u001b[2m => => # per)                                                                  \n",
      "\u001b[0m\u001b[2m => => #   Downloading tblib-3.1.0-py3-none-any.whl.metadata (25 kB)           \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.5s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   1.9s\n",
      "\u001b[2m => => # al/lib/python3.12/dist-packages (from graphene<4,>=3->sagemaker>=2.145\n",
      "\u001b[0m\u001b[2m => => # .0->sagemaker-ssh-helper) (4.15.0)                                    \n",
      "\u001b[0m\u001b[2m => => # Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3,>=2.2->sage\n",
      "\u001b[0m\u001b[2m => => # maker>=2.145.0->sagemaker-ssh-helper)                                 \n",
      "\u001b[0m\u001b[2m => => #   Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)            \n",
      "\u001b[0m\u001b[2m => => #   Preparing metadata (setup.py): started                              \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.6s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   2.0s\n",
      "\u001b[2m => => # al/lib/python3.12/dist-packages (from graphene<4,>=3->sagemaker>=2.145\n",
      "\u001b[0m\u001b[2m => => # .0->sagemaker-ssh-helper) (4.15.0)                                    \n",
      "\u001b[0m\u001b[2m => => # Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3,>=2.2->sage\n",
      "\u001b[0m\u001b[2m => => # maker>=2.145.0->sagemaker-ssh-helper)                                 \n",
      "\u001b[0m\u001b[2m => => #   Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)            \n",
      "\u001b[0m\u001b[2m => => #   Preparing metadata (setup.py): started                              \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.8s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   2.2s\n",
      "\u001b[2m => => # al/lib/python3.12/dist-packages (from graphene<4,>=3->sagemaker>=2.145\n",
      "\u001b[0m\u001b[2m => => # .0->sagemaker-ssh-helper) (4.15.0)                                    \n",
      "\u001b[0m\u001b[2m => => # Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3,>=2.2->sage\n",
      "\u001b[0m\u001b[2m => => # maker>=2.145.0->sagemaker-ssh-helper)                                 \n",
      "\u001b[0m\u001b[2m => => #   Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)            \n",
      "\u001b[0m\u001b[2m => => #   Preparing metadata (setup.py): started                              \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.9s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   2.3s\n",
      "\u001b[2m => => # .0->sagemaker-ssh-helper) (4.15.0)                                    \n",
      "\u001b[0m\u001b[2m => => # Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3,>=2.2->sage\n",
      "\u001b[0m\u001b[2m => => # maker>=2.145.0->sagemaker-ssh-helper)                                 \n",
      "\u001b[0m\u001b[2m => => #   Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)            \n",
      "\u001b[0m\u001b[2m => => #   Preparing metadata (setup.py): started                              \n",
      "\u001b[0m\u001b[2m => => #   Preparing metadata (setup.py): finished with status 'done'          \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.0s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   2.4s\n",
      "\u001b[2m => => # r>=2.145.0->sagemaker-ssh-helper) (4.10.0)                            \n",
      "\u001b[0m\u001b[2m => => # Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.\n",
      "\u001b[0m\u001b[2m => => # 12/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fas\n",
      "\u001b[0m\u001b[2m => => # tapi->sagemaker>=2.145.0->sagemaker-ssh-helper) (1.3.1)               \n",
      "\u001b[0m\u001b[2m => => # Collecting pytz>=2020.1 (from pandas->sagemaker>=2.145.0->sagemaker-ss\n",
      "\u001b[0m\u001b[2m => => # h-helper)                                                             \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.1s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   2.5s\n",
      "\u001b[2m => => # Requirement already satisfied: dill>=0.4.0 in /usr/local/lib/python3.1\n",
      "\u001b[0m\u001b[2m => => # 2/dist-packages (from pathos->sagemaker>=2.145.0->sagemaker-ssh-helper\n",
      "\u001b[0m\u001b[2m => => # ) (0.4.0)                                                             \n",
      "\u001b[0m\u001b[2m => => # Collecting pox>=0.3.6 (from pathos->sagemaker>=2.145.0->sagemaker-ssh-\n",
      "\u001b[0m\u001b[2m => => # helper)                                                               \n",
      "\u001b[0m\u001b[2m => => #   Downloading pox-0.3.6-py3-none-any.whl.metadata (8.0 kB)            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.2s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   2.6s\n",
      "\u001b[2m => => # Downloading s5cmd-0.3.3-py3-none-manylinux1_x86_64.manylinux_2_28_x86_\n",
      "\u001b[0m\u001b[2m => => # 64.manylinux_2_5_x86_64.whl (5.0 MB)                                  \n",
      "\u001b[0m\u001b[2m => => #    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.0/5.0 MB 233.6 MB/s  0:0\n",
      "\u001b[0m\u001b[2m => => # 0:00                                                                  \n",
      "\u001b[0m\u001b[2m => => # Downloading sagemaker_ssh_helper-2.3.0-py3-none-any.whl (102 kB)      \n",
      "\u001b[0m\u001b[2m => => # Downloading sagemaker-2.251.1-py3-none-any.whl (1.7 MB)               \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.3s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   2.7s\n",
      "\u001b[2m => => # Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)    \n",
      "\u001b[0m\u001b[2m => => # Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)              \n",
      "\u001b[0m\u001b[2m => => # Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)              \n",
      "\u001b[0m\u001b[2m => => # Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)              \n",
      "\u001b[0m\u001b[2m => => # Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)                  \n",
      "\u001b[0m\u001b[2m => => # Downloading packaging-24.2-py3-none-any.whl (65 kB)                   \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.4s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   2.8s\n",
      "\u001b[2m => => # Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux20\n",
      "\u001b[0m\u001b[2m => => # 14_x86_64.whl (12.0 MB)                                               \n",
      "\u001b[0m\u001b[2m => => #    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.0/12.0 MB 456.3 MB/s  0\n",
      "\u001b[0m\u001b[2m => => # :00:00                                                                \n",
      "\u001b[0m\u001b[2m => => # Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)                 \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.6s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   3.0s\n",
      "\u001b[2m => => # Downloading pathos-0.3.4-py3-none-any.whl (82 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading multiprocess-0.70.18-py312-none-any.whl (150 kB)          \n",
      "\u001b[0m\u001b[2m => => # Downloading pox-0.3.6-py3-none-any.whl (29 kB)                        \n",
      "\u001b[0m\u001b[2m => => # Downloading ppft-1.7.7-py3-none-any.whl (56 kB)                       \n",
      "\u001b[0m\u001b[2m => => # Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)                 \n",
      "\u001b[0m\u001b[2m => => # Building wheels for collected packages: antlr4-python3-runtime        \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.8s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   3.2s\n",
      "\u001b[2m => => #  pip 25.3 will enforce this behaviour change. A possible replacement i\n",
      "\u001b[0m\u001b[2m => => # s to use the standardized build interface by setting the `--use-pep517\n",
      "\u001b[0m\u001b[2m => => # ` option, (possibly combined with `--no-build-isolation`), or adding a\n",
      "\u001b[0m\u001b[2m => => #  `pyproject.toml` file to the source tree of 'antlr4-python3-runtime'.\n",
      "\u001b[0m\u001b[2m => => #  Discussion can be found at https://github.com/pypa/pip/issues/6334   \n",
      "\u001b[0m\u001b[2m => => #   Building wheel for antlr4-python3-runtime (setup.py): started       \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.9s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   3.3s\n",
      "\u001b[2m => => #  pip 25.3 will enforce this behaviour change. A possible replacement i\n",
      "\u001b[0m\u001b[2m => => # s to use the standardized build interface by setting the `--use-pep517\n",
      "\u001b[0m\u001b[2m => => # ` option, (possibly combined with `--no-build-isolation`), or adding a\n",
      "\u001b[0m\u001b[2m => => #  `pyproject.toml` file to the source tree of 'antlr4-python3-runtime'.\n",
      "\u001b[0m\u001b[2m => => #  Discussion can be found at https://github.com/pypa/pip/issues/6334   \n",
      "\u001b[0m\u001b[2m => => #   Building wheel for antlr4-python3-runtime (setup.py): started       \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.1s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   3.5s\n",
      "\u001b[2m => => #  pip 25.3 will enforce this behaviour change. A possible replacement i\n",
      "\u001b[0m\u001b[2m => => # s to use the standardized build interface by setting the `--use-pep517\n",
      "\u001b[0m\u001b[2m => => # ` option, (possibly combined with `--no-build-isolation`), or adding a\n",
      "\u001b[0m\u001b[2m => => #  `pyproject.toml` file to the source tree of 'antlr4-python3-runtime'.\n",
      "\u001b[0m\u001b[2m => => #  Discussion can be found at https://github.com/pypa/pip/issues/6334   \n",
      "\u001b[0m\u001b[2m => => #   Building wheel for antlr4-python3-runtime (setup.py): started       \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.1s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   3.5s\n",
      "\u001b[2m => => # ` option, (possibly combined with `--no-build-isolation`), or adding a\n",
      "\u001b[0m\u001b[2m => => #  `pyproject.toml` file to the source tree of 'antlr4-python3-runtime'.\n",
      "\u001b[0m\u001b[2m => => #  Discussion can be found at https://github.com/pypa/pip/issues/6334   \n",
      "\u001b[0m\u001b[2m => => #   Building wheel for antlr4-python3-runtime (setup.py): started       \n",
      "\u001b[0m\u001b[2m => => #   Building wheel for antlr4-python3-runtime (setup.py): finished with \n",
      "\u001b[0m\u001b[2m => => # status 'done'                                                         \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.3s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   3.7s\n",
      "\u001b[2m => => #   Created wheel for antlr4-python3-runtime: filename=antlr4_python3_ru\n",
      "\u001b[0m\u001b[2m => => # ntime-4.9.3-py3-none-any.whl size=144590 sha256=16d54fc6ed5c0bdb15823f\n",
      "\u001b[0m\u001b[2m => => # cc281892737f79523fdacafd476f61d17079b63338                            \n",
      "\u001b[0m\u001b[2m => => #   Stored in directory: /tmp/pip-ephem-wheel-cache-xrxdv5fl/wheels/1f/b\n",
      "\u001b[0m\u001b[2m => => # e/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd               \n",
      "\u001b[0m\u001b[2m => => # Successfully built antlr4-python3-runtime                             \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.4s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   3.8s\n",
      "\u001b[2m => => #   Created wheel for antlr4-python3-runtime: filename=antlr4_python3_ru\n",
      "\u001b[0m\u001b[2m => => # ntime-4.9.3-py3-none-any.whl size=144590 sha256=16d54fc6ed5c0bdb15823f\n",
      "\u001b[0m\u001b[2m => => # cc281892737f79523fdacafd476f61d17079b63338                            \n",
      "\u001b[0m\u001b[2m => => #   Stored in directory: /tmp/pip-ephem-wheel-cache-xrxdv5fl/wheels/1f/b\n",
      "\u001b[0m\u001b[2m => => # e/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd               \n",
      "\u001b[0m\u001b[2m => => # Successfully built antlr4-python3-runtime                             \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.6s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   4.0s\n",
      "\u001b[2m => => #   Created wheel for antlr4-python3-runtime: filename=antlr4_python3_ru\n",
      "\u001b[0m\u001b[2m => => # ntime-4.9.3-py3-none-any.whl size=144590 sha256=16d54fc6ed5c0bdb15823f\n",
      "\u001b[0m\u001b[2m => => # cc281892737f79523fdacafd476f61d17079b63338                            \n",
      "\u001b[0m\u001b[2m => => #   Stored in directory: /tmp/pip-ephem-wheel-cache-xrxdv5fl/wheels/1f/b\n",
      "\u001b[0m\u001b[2m => => # e/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd               \n",
      "\u001b[0m\u001b[2m => => # Successfully built antlr4-python3-runtime                             \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.7s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   4.1s\n",
      "\u001b[2m => => #   Created wheel for antlr4-python3-runtime: filename=antlr4_python3_ru\n",
      "\u001b[0m\u001b[2m => => # ntime-4.9.3-py3-none-any.whl size=144590 sha256=16d54fc6ed5c0bdb15823f\n",
      "\u001b[0m\u001b[2m => => # cc281892737f79523fdacafd476f61d17079b63338                            \n",
      "\u001b[0m\u001b[2m => => #   Stored in directory: /tmp/pip-ephem-wheel-cache-xrxdv5fl/wheels/1f/b\n",
      "\u001b[0m\u001b[2m => => # e/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd               \n",
      "\u001b[0m\u001b[2m => => # Successfully built antlr4-python3-runtime                             \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.9s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   4.3s\n",
      "\u001b[2m => => #   Created wheel for antlr4-python3-runtime: filename=antlr4_python3_ru\n",
      "\u001b[0m\u001b[2m => => # ntime-4.9.3-py3-none-any.whl size=144590 sha256=16d54fc6ed5c0bdb15823f\n",
      "\u001b[0m\u001b[2m => => # cc281892737f79523fdacafd476f61d17079b63338                            \n",
      "\u001b[0m\u001b[2m => => #   Stored in directory: /tmp/pip-ephem-wheel-cache-xrxdv5fl/wheels/1f/b\n",
      "\u001b[0m\u001b[2m => => # e/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd               \n",
      "\u001b[0m\u001b[2m => => # Successfully built antlr4-python3-runtime                             \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.0s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   4.4s\n",
      "\u001b[2m => => #   Created wheel for antlr4-python3-runtime: filename=antlr4_python3_ru\n",
      "\u001b[0m\u001b[2m => => # ntime-4.9.3-py3-none-any.whl size=144590 sha256=16d54fc6ed5c0bdb15823f\n",
      "\u001b[0m\u001b[2m => => # cc281892737f79523fdacafd476f61d17079b63338                            \n",
      "\u001b[0m\u001b[2m => => #   Stored in directory: /tmp/pip-ephem-wheel-cache-xrxdv5fl/wheels/1f/b\n",
      "\u001b[0m\u001b[2m => => # e/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd               \n",
      "\u001b[0m\u001b[2m => => # Successfully built antlr4-python3-runtime                             \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.1s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   4.4s\n",
      "\u001b[2m => => # Successfully built antlr4-python3-runtime                             \n",
      "\u001b[0m\u001b[2m => => # Installing collected packages: schema, pytz, antlr4-python3-runtime, t\n",
      "\u001b[0m\u001b[2m => => # zdata, tblib, smdebug-rulesconfig, s5cmd, protobuf, ppft, pox, platfor\n",
      "\u001b[0m\u001b[2m => => # mdirs, packaging, omegaconf, numpy, multiprocess, mock, graphql-core, \n",
      "\u001b[0m\u001b[2m => => # google-pasta, pathos, pandas, graphql-relay, docker, graphene, sagemak\n",
      "\u001b[0m\u001b[2m => => # er-core, sagemaker, sagemaker-ssh-helper                              \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.2s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   4.6s\n",
      "\u001b[2m => => # Successfully built antlr4-python3-runtime                             \n",
      "\u001b[0m\u001b[2m => => # Installing collected packages: schema, pytz, antlr4-python3-runtime, t\n",
      "\u001b[0m\u001b[2m => => # zdata, tblib, smdebug-rulesconfig, s5cmd, protobuf, ppft, pox, platfor\n",
      "\u001b[0m\u001b[2m => => # mdirs, packaging, omegaconf, numpy, multiprocess, mock, graphql-core, \n",
      "\u001b[0m\u001b[2m => => # google-pasta, pathos, pandas, graphql-relay, docker, graphene, sagemak\n",
      "\u001b[0m\u001b[2m => => # er-core, sagemaker, sagemaker-ssh-helper                              \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.4s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   4.7s\n",
      "\u001b[2m => => # Successfully built antlr4-python3-runtime                             \n",
      "\u001b[0m\u001b[2m => => # Installing collected packages: schema, pytz, antlr4-python3-runtime, t\n",
      "\u001b[0m\u001b[2m => => # zdata, tblib, smdebug-rulesconfig, s5cmd, protobuf, ppft, pox, platfor\n",
      "\u001b[0m\u001b[2m => => # mdirs, packaging, omegaconf, numpy, multiprocess, mock, graphql-core, \n",
      "\u001b[0m\u001b[2m => => # google-pasta, pathos, pandas, graphql-relay, docker, graphene, sagemak\n",
      "\u001b[0m\u001b[2m => => # er-core, sagemaker, sagemaker-ssh-helper                              \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.5s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   4.9s\n",
      "\u001b[2m => => # Installing collected packages: schema, pytz, antlr4-python3-runtime, t\n",
      "\u001b[0m\u001b[2m => => # zdata, tblib, smdebug-rulesconfig, s5cmd, protobuf, ppft, pox, platfor\n",
      "\u001b[0m\u001b[2m => => # mdirs, packaging, omegaconf, numpy, multiprocess, mock, graphql-core, \n",
      "\u001b[0m\u001b[2m => => # google-pasta, pathos, pandas, graphql-relay, docker, graphene, sagemak\n",
      "\u001b[0m\u001b[2m => => # er-core, sagemaker, sagemaker-ssh-helper                              \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: protobuf                                      \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.6s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   5.0s\n",
      "\u001b[2m => => # google-pasta, pathos, pandas, graphql-relay, docker, graphene, sagemak\n",
      "\u001b[0m\u001b[2m => => # er-core, sagemaker, sagemaker-ssh-helper                              \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: protobuf                                      \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: protobuf 6.32.1                      \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling protobuf-6.32.1:                                     \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled protobuf-6.32.1                        \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.7s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   5.1s\n",
      "\u001b[2m => => # er-core, sagemaker, sagemaker-ssh-helper                              \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: protobuf                                      \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: protobuf 6.32.1                      \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling protobuf-6.32.1:                                     \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled protobuf-6.32.1                        \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: packaging                                     \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.9s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   5.3s\n",
      "\u001b[2m => => #       Successfully uninstalled protobuf-6.32.1                        \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: packaging                                     \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: packaging 25.0                       \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.1s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   5.5s\n",
      "\u001b[2m => => #     Found existing installation: packaging 25.0                       \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.1s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   5.5s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.3s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   5.7s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.4s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   5.8s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.6s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   6.0s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.7s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   6.1s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.9s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   6.3s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.0s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   6.4s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.2s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   6.6s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.3s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   6.7s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.5s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   6.9s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.6s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   7.0s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.8s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   7.2s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.9s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   7.3s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.1s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   7.5s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.2s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   7.6s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.4s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   7.8s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.5s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   7.9s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.7s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   8.1s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.8s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   8.2s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.0s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   8.4s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.1s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   8.5s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.3s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   8.7s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.4s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   8.8s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.6s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   9.0s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.7s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   9.1s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.9s (7/8)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   9.3s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.0s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   9.4s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.2s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   9.6s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.3s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   9.7s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.5s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests   9.9s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.6s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  10.0s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.8s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  10.2s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.9s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  10.3s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.1s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  10.5s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.2s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  10.6s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.4s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  10.8s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.5s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  10.9s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.7s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  11.1s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.8s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  11.2s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.0s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  11.4s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.1s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  11.5s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.3s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  11.7s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.4s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  11.8s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.6s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  12.0s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.7s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  12.1s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.9s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  12.3s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.0s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  12.4s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.2s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  12.6s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.3s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  12.7s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.5s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  12.9s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.6s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  13.0s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.8s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  13.2s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.9s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  13.3s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.1s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  13.5s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.2s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  13.6s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.4s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  13.8s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.5s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  13.9s\n",
      "\u001b[2m => => #     Uninstalling packaging-25.0:                                      \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled packaging-25.0                         \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: numpy                                         \n",
      "\u001b[0m\u001b[2m => => #     Found existing installation: numpy 2.2.6                          \n",
      "\u001b[0m\u001b[2m => => #     Uninstalling numpy-2.2.6:                                         \n",
      "\u001b[0m\u001b[2m => => #       Successfully uninstalled numpy-2.2.6                            \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.7s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.1s\n",
      "\u001b[2m => => # WARNING: Running pip as the 'root' user can result in broken permissio\n",
      "\u001b[0m\u001b[2m => => # ns and conflicting behaviour with the system package manager, possibly\n",
      "\u001b[0m\u001b[2m => => #  rendering your system unusable. It is recommended to use a virtual en\n",
      "\u001b[0m\u001b[2m => => # vironment instead: https://pip.pypa.io/warnings/venv. Use the --root-u\n",
      "\u001b[0m\u001b[2m => => # ser-action option if you know what you are doing and want to suppress \n",
      "\u001b[0m\u001b[2m => => # this warning.                                                         \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.8s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.2s\n",
      "\u001b[2m => => # WARNING: Running pip as the 'root' user can result in broken permissio\n",
      "\u001b[0m\u001b[2m => => # ns and conflicting behaviour with the system package manager, possibly\n",
      "\u001b[0m\u001b[2m => => #  rendering your system unusable. It is recommended to use a virtual en\n",
      "\u001b[0m\u001b[2m => => # vironment instead: https://pip.pypa.io/warnings/venv. Use the --root-u\n",
      "\u001b[0m\u001b[2m => => # ser-action option if you know what you are doing and want to suppress \n",
      "\u001b[0m\u001b[2m => => # this warning.                                                         \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.0s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.4s\n",
      "\u001b[2m => => # WARNING: Running pip as the 'root' user can result in broken permissio\n",
      "\u001b[0m\u001b[2m => => # ns and conflicting behaviour with the system package manager, possibly\n",
      "\u001b[0m\u001b[2m => => #  rendering your system unusable. It is recommended to use a virtual en\n",
      "\u001b[0m\u001b[2m => => # vironment instead: https://pip.pypa.io/warnings/venv. Use the --root-u\n",
      "\u001b[0m\u001b[2m => => # ser-action option if you know what you are doing and want to suppress \n",
      "\u001b[0m\u001b[2m => => # this warning.                                                         \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.1s (7/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.5s\n",
      "\u001b[2m => => # WARNING: Running pip as the 'root' user can result in broken permissio\n",
      "\u001b[0m\u001b[2m => => # ns and conflicting behaviour with the system package manager, possibly\n",
      "\u001b[0m\u001b[2m => => #  rendering your system unusable. It is recommended to use a virtual en\n",
      "\u001b[0m\u001b[2m => => # vironment instead: https://pip.pypa.io/warnings/venv. Use the --root-u\n",
      "\u001b[0m\u001b[2m => => # ser-action option if you know what you are doing and want to suppress \n",
      "\u001b[0m\u001b[2m => => # this warning.                                                         \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.3s (8/8)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m\u001b[34m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.7s\n",
      "\u001b[0m                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "\u001b[6A\u001b[0G\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.4s (8/9)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m\u001b[34m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.7s\n",
      "\u001b[0m => exporting to image                                                     0.2s\n",
      " => => exporting layers                                                    0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.6s (8/9)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m\u001b[34m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.7s\n",
      "\u001b[0m => exporting to image                                                     0.3s\n",
      " => => exporting layers                                                    0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.7s (8/9)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m\u001b[34m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.7s\n",
      "\u001b[0m => exporting to image                                                     0.5s\n",
      " => => exporting layers                                                    0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.9s (8/9)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m\u001b[34m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.7s\n",
      "\u001b[0m => exporting to image                                                     0.6s\n",
      " => => exporting layers                                                    0.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.0s (8/9)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m\u001b[34m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.7s\n",
      "\u001b[0m => exporting to image                                                     0.8s\n",
      " => => exporting layers                                                    0.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.2s (8/9)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m\u001b[34m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.7s\n",
      "\u001b[0m => exporting to image                                                     0.9s\n",
      " => => exporting layers                                                    0.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.3s (8/9)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m\u001b[34m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.7s\n",
      "\u001b[0m => exporting to image                                                     1.1s\n",
      " => => exporting layers                                                    1.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.5s (8/9)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m\u001b[34m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.7s\n",
      "\u001b[0m => exporting to image                                                     1.2s\n",
      " => => exporting layers                                                    1.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.6s (8/9)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m\u001b[34m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.7s\n",
      "\u001b[0m => exporting to image                                                     1.4s\n",
      " => => exporting layers                                                    1.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.6s (8/9)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m\u001b[34m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.7s\n",
      "\u001b[0m => exporting to image                                                     1.4s\n",
      "\u001b[34m => => exporting layers                                                    1.4s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.7s (9/9) FINISHED                                docker:default\n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 466B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/vllm/vllm-openai:v0.10.2        0.5s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/vllm/vllm-openai:v0.10.2@sha256:607442e407b0fea9  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 410B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => [3/4] COPY app/ /app                                                   0.0s\n",
      "\u001b[0m\u001b[34m => [4/4] RUN python3 -m pip install s5cmd sagemaker-ssh-helper requests  14.7s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     1.4s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    1.4s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:7107e53d65826d1ebb73d745561d7109444941bd0c4d9  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/sagemaker_endpoint/vllm:v0.10.2                 0.0s\n",
      "\u001b[0m\u001b[?25hThe push refers to repository [340636688520.dkr.ecr.us-west-2.amazonaws.com/sagemaker_endpoint/vllm]\n",
      "\n",
      "\u001b[1Bde13b9d9: Preparing \n",
      "\u001b[1B198b76a1: Preparing \n",
      "\u001b[1B8c152a28: Preparing \n",
      "\u001b[1Bb2e7aca1: Preparing \n",
      "\u001b[1B3a025908: Preparing \n",
      "\u001b[1B8c4aba2a: Preparing \n",
      "\u001b[1B47eba856: Preparing \n",
      "\u001b[1B9b1b5270: Preparing \n",
      "\u001b[1Bb1a036d5: Preparing \n",
      "\u001b[1B22c728ec: Preparing \n",
      "\u001b[1Bd7455786: Preparing \n",
      "\u001b[1B8bec5f9f: Preparing \n",
      "\u001b[1Bb22983cf: Preparing \n",
      "\u001b[1B85296aa7: Preparing \n",
      "\u001b[1Bbf6df512: Preparing \n",
      "\u001b[1Ba164db28: Preparing \n",
      "\u001b[1B2159345e: Preparing \n",
      "\u001b[1Bb892ece2: Preparing \n",
      "\u001b[1Bcec85f64: Preparing \n",
      "\u001b[1B7f51107a: Preparing \n",
      "\u001b[1Bf3542ffa: Preparing \n",
      "\u001b[1B3244400a: Preparing \n",
      "\u001b[1B74064ac3: Preparing \n",
      "\u001b[1B77eb665d: Preparing \n",
      "\u001b[1B0d2ed199: Preparing \n",
      "\u001b[1Bae9b9700: Preparing \n",
      "\u001b[1B510c7b4b: Preparing \n",
      "\u001b[1B58f70e37: Preparing \n",
      "\u001b[1B5f276e98: Preparing \n",
      "\u001b[1B43fcce68: Preparing \n",
      "\u001b[1Bd84069cf: Preparing \n",
      "\u001b[1B1d6040fc: Preparing \n",
      "\u001b[28Bc4aba2a: Waiting g \n",
      "\u001b[28B7eba856: Waiting g \n",
      "\u001b[18Bv0.10.2: digest: sha256:d076ab776b4440313704837464f1d1201c5325c94756187f0c98d73a5db7f2d5 size: 7661\n"
     ]
    }
   ],
   "source": [
    "cmd = f\"VLLM_REPO={VLLM_REPO} VLLM_VERSION={VLLM_VERSION} REPO_NAMESPACE={REPO_NAMESPACE} ACCOUNT={ACCOUNT} REGION={REGION} bash ./build_and_push.sh \"\n",
    "print(\"Runging:\", cmd)\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy on SageMaker\n",
    "\n",
    "define the model and deploy on SageMaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.40.38)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.40.39-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.251.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.35.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting modelscope\n",
      "  Downloading modelscope-1.30.0-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting s5cmd\n",
      "  Downloading s5cmd-0.3.3-py3-none-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting botocore<1.41.0,>=1.40.39 (from boto3)\n",
      "  Downloading botocore-1.40.39-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.41.0,>=1.40.39->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.41.0,>=1.40.39->boto3) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.39->boto3) (1.17.0)\n",
      "Requirement already satisfied: attrs<26,>=24 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (25.3.0)\n",
      "Requirement already satisfied: cloudpickle>=2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.1.1)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.117.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: graphene<4,>=3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.4.3)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.11.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.25.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: omegaconf<3,>=2.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.3.0)\n",
      "Requirement already satisfied: packaging<25,>=23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (24.2)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.3.2)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.3.4)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.4.0)\n",
      "Requirement already satisfied: protobuf<6.32,>=3.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.31.1)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.32.5)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.59)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.1.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.67.1)\n",
      "Requirement already satisfied: uvicorn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.37.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from graphene<4,>=3->sagemaker) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from graphene<4,>=3->sagemaker) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from graphene<4,>=3->sagemaker) (4.15.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.23.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from omegaconf<3,>=2.2->sagemaker) (4.9.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.9.2)\n",
      "Requirement already satisfied: rich<15.0.0,>=13.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (14.1.0)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.27.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.23.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich<15.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich<15.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.19.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2025.9.18)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (2025.9.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub)\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from modelscope) (80.9.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (2025.8.3)\n",
      "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fastapi->sagemaker) (0.48.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from starlette<0.49.0,>=0.40.0->fastapi->sagemaker) (4.11.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi->sagemaker) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi->sagemaker) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2025.2)\n",
      "Requirement already satisfied: ppft>=1.7.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.7)\n",
      "Requirement already satisfied: dill>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.4.0)\n",
      "Requirement already satisfied: pox>=0.3.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.18 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.18)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn->sagemaker) (8.3.0)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn->sagemaker) (0.16.0)\n",
      "Downloading boto3-1.40.39-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.40.39-py3-none-any.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m169.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m192.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.3/563.3 kB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m212.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m200.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading modelscope-1.30.0-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m175.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading s5cmd-0.3.3-py3-none-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m173.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Installing collected packages: safetensors, s5cmd, hf-xet, modelscope, huggingface_hub, botocore, tokenizers, transformers, boto3\n",
      "\u001b[2K  Attempting uninstall: botocore1m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/9\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Found existing installation: botocore 1.40.38━━━━━━━━━━━━━\u001b[0m \u001b[32m4/9\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Uninstalling botocore-1.40.38:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/9\u001b[0m [huggingface_hub]\n",
      "\u001b[2K      Successfully uninstalled botocore-1.40.38━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/9\u001b[0m [huggingface_hub]\n",
      "\u001b[2K  Attempting uninstall: boto3━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m7/9\u001b[0m [transformers]\n",
      "\u001b[2K    Found existing installation: boto3 1.40.38[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m7/9\u001b[0m [transformers]\n",
      "\u001b[2K    Uninstalling boto3-1.40.38:━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m7/9\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled boto3-1.40.38╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m7/9\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [boto3]32m8/9\u001b[0m [boto3]rs]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.42.38 requires botocore==1.40.38, but you have botocore 1.40.39 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.40.39 botocore-1.40.39 hf-xet-1.1.10 huggingface_hub-0.35.1 modelscope-1.30.0 s5cmd-0.3.3 safetensors-0.6.2 tokenizers-0.22.1 transformers-4.56.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U boto3 sagemaker transformers huggingface_hub modelscope s5cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Init SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sess.default_bucket()\n",
    "\n",
    "sagemaker_client = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Download and upload model file\n",
    "\n",
    "Firstly, you need to prepare model weights and upload to S3. You can download from HuggingFace, ModelScope or upload your own model. \n",
    "\n",
    "If you want vllm to automatically pull the model when it starts, this step can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_model_path: ./models/openai-gpt-oss-20b\n"
     ]
    }
   ],
   "source": [
    "model_name = MODEL_ID.replace(\"/\", \"-\").replace(\".\", \"-\")\n",
    "local_model_path = \"./models/\" + model_name\n",
    "# s3_model_path = f\"s3://{default_bucket}/models/\" + model_name\n",
    "s3_model_path = f\"s3://{default_bucket}/pretrained-models/\" + MODEL_ID\n",
    "\n",
    "%mkdir -p code {local_model_path}\n",
    "\n",
    "print(\"local_model_path:\", local_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Option 1: Global region (download from HuggingFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Fetching 18 files:   0%|                                 | 0/18 [00:00<?, ?it/s]Still waiting to acquire lock on models/openai-gpt-oss-20b/.cache/huggingface/.gitignore.lock (elapsed: 0.1 seconds)\n",
      "Downloading 'model-00001-of-00002.safetensors' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/aoe4E07IMh7reFyUkVoVk040mQk=.4fbe328ab445455d6f58dc73852b85873bd626986310abd91cd4d2ce3245eaea.incomplete'\n",
      "Downloading 'USAGE_POLICY' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/nuppLbVBwlGNavFsJGV4eMxPJec=.b030f63aecc61cbaf2316a7b6401254f4312df74.incomplete'\n",
      "Downloading 'model-00000-of-00002.safetensors' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/rNcDyGZpF6SnrZxn4k3RDjVGER0=.16d0f997dcfc4462089d536bffe51b4bcea2f872f5c430be09ef8ed392312427.incomplete'\n",
      "Downloading 'original/model.safetensors' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/original/xGOKKLRSlIhH692hSVvI1-gpoa8=.3340a61d1a0391e8c5b5d3463d18d4c48129a84bbc04a554c762c99020aa06ed.incomplete'\n",
      "Downloading 'model.safetensors.index.json' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/yVzAsSxRSINSz-tQbpx-TLpfkLU=.ae08521471ab125be4af84d0e51ecfc245830119.incomplete'\n",
      "Downloading 'model-00002-of-00002.safetensors' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/Dr_lZJDwE1cnGAQMwA77jJEQIk8=.a18106b209e9ab35c3406db4f6f12a927364a058b21e9d1373d682e20674b303.incomplete'\n",
      "Downloading 'original/dtypes.json' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/original/ZZTepSZYYa8e5qZ7iN-vu9zbj2o=.07e91493fc3ebf901d7d18b1309795b3f5e466aa.incomplete'\n",
      "\n",
      "Downloading '.gitattributes' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.52373fe24473b1aa44333d318f578ae6bf04b49b.incomplete'\n",
      "Downloading 'config.json' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.8fb5a4a03376ab5a12afd94b4ed93da61edf5b1c.incomplete'\n",
      "USAGE_POLICY: 100%|████████████████████████████| 200/200 [00:00<00:00, 1.95MB/s]\u001b[A\n",
      "Downloading 'LICENSE' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/DhCjcNQuMpl4FL346qr3tvNUCgY=.7a4a3ea2424c09fbe48d455aed1eaa94d9124835.incomplete'\n",
      "\n",
      "Downloading 'original/config.json' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/original/8_PA_wEVGiVa2goH2H4KQOQpvVY=.bd6a33e55b68b6734c932c44bd98f376d492dad9.incomplete'\n",
      "model.safetensors.index.json: 0.00B [00:00, ?B/s]Downloading 'special_tokens_map.json' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/ahkChHUJFxEmOdq5GDFEmerRzCY=.73bd12e55e2004cdfff088f85092b39dba2ccdd0.incomplete'\n",
      "\u001b[ADownloading 'metal/model.bin' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/metal/mBG94Lz8EYH5gU8b5axgj2RF9Tk=.725b7f996b5a226d922f034a731aefc398652f670dcafc2efd78620509a0fef1.incomplete'\n",
      "\n",
      "\n",
      ".gitattributes: 0.00B [00:00, ?B/s]Downloading 'tokenizer_config.json' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.c021cddb0a9dd35b1bf83a9f145be2d9b3757891.incomplete'\n",
      "\u001b[A\u001b[ADownloading 'generation_config.json' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/3EVKVggOldJcKSsGjSdoUCN1AyQ=.86f91466555bd40e3de0b1edee3d5d82f4ccdbfe.incomplete'\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/USAGE_POLICY\n",
      "\n",
      "\n",
      "\n",
      "Downloading 'tokenizer.json' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.0614fe83cadab421296e664e1f48f4261fa8fef6e03e63bb75c20f38e37d07d3.incomplete'\n",
      "model.safetensors.index.json: 36.4kB [00:00, 4.55MB/s]\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/model.safetensors.index.json\n",
      ".gitattributes: 1.57kB [00:00, 219kB/s]\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/.gitattributes\n",
      "\n",
      "dtypes.json: 13.1kB [00:00, 3.02MB/s]\n",
      "\n",
      "\n",
      "LICENSE: 0.00B [00:00, ?B/s]Download complete. Moving file to models/openai-gpt-oss-20b/original/dtypes.json\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "special_tokens_map.json:   0%|                       | 0.00/98.0 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "config.json: 1.81kB [00:00, 301kB/s]                  | 0.00/376 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/config.json\n",
      "LICENSE: 11.4kB [00:00, 3.43MB/s]\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/LICENSE\n",
      "special_tokens_map.json: 100%|███████████████| 98.0/98.0 [00:00<00:00, 34.5kB/s]\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/special_tokens_map.json\n",
      "Fetching 18 files:   6%|█▍                       | 1/18 [00:00<00:04,  4.17it/s]\n",
      "tokenizer_config.json: 0.00B [00:00, ?B/s]\u001b[A\n",
      "\n",
      "config.json: 100%|█████████████████████████████| 376/376 [00:00<00:00, 86.8kB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/original/config.json\n",
      "tokenizer_config.json: 4.20kB [00:00, 2.38MB/s]\n",
      "generation_config.json: 100%|███████████████████| 177/177 [00:00<00:00, 128kB/s]Download complete. Moving file to models/openai-gpt-oss-20b/tokenizer_config.json\n",
      "\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/generation_config.json\n",
      "Downloading 'chat_template.jinja' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/yIUQ6Jg7XpBWXEkozaEkS2ih05g=.dc7bb11927d29f653ba2740f2db2c688fd77592f.incomplete'\n",
      "\n",
      "chat_template.jinja: 0.00B [00:00, ?B/s]\u001b[A\n",
      "\n",
      "chat_template.jinja: 16.7kB [00:00, 33.3MB/s]       | 0.00/4.80G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/chat_template.jinja\n",
      "Downloading 'README.md' to 'models/openai-gpt-oss-20b/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.f6e25105129ce88f068afff463e0db36024e9ae8.incomplete'\n",
      "\n",
      "README.md: 7.09kB [00:00, 37.4MB/s]\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/README.md\n",
      "\n",
      "model-00000-of-00002.safetensors:   0%|             | 0.00/4.79G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   0%|                   | 0.00/13.8G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   0%|             | 0.00/4.17G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   0%|                              | 0.00/13.8G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizer.json:   0%|                               | 0.00/27.9M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizer.json: 100%|██████████████████████| 27.9M/27.9M [00:00<00:00, 53.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/tokenizer.json\n",
      "\n",
      "\n",
      "\n",
      "original/model.safetensors:   0%|        | 98.6k/13.8G [00:00<27:58:49, 137kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   0%| | 39.1k/4.17G [00:00<23:38:59, 49.0kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   0%|        | 1.03M/13.8G [00:00<2:27:33, 1.55MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   0%|                   | 104k/13.8G [00:01<38:29:03, 99.3kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   0%|          | 3.90M/13.8G [00:01<45:15, 5.07MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   0%|                   | 1.83M/13.8G [00:01<2:41:57, 1.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   0%|    | 8.43M/4.17G [00:01<12:41, 5.47MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   0%|          | 12.0M/13.8G [00:01<26:16, 8.72MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   0%|    | 4.55M/4.79G [00:01<34:39, 2.30MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   2%|    | 77.0M/4.17G [00:02<01:12, 56.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   0%|          | 20.3M/13.8G [00:02<15:12, 15.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|  | 144k/4.80G [00:02<21:48:31, 61.1kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   3%|▏    | 144M/4.17G [00:02<00:41, 97.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   0%|    | 4.86M/4.79G [00:02<42:02, 1.90MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   0%|                   | 4.70M/13.8G [00:02<1:37:48, 2.34MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 708k/4.80G [00:02<3:41:31, 361kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   0%|          | 33.4M/13.8G [00:02<13:00, 17.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   0%|                     | 21.9M/13.8G [00:02<17:21, 13.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   0%|          | 67.9M/13.8G [00:02<05:00, 45.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   0%|                     | 24.9M/13.8G [00:02<16:42, 13.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 3.61M/4.80G [00:03<42:08, 1.90MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   6%|▍     | 271M/4.17G [00:03<00:28, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   1%|           | 110M/13.8G [00:03<02:51, 79.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   0%|    | 5.12M/4.79G [00:03<58:51, 1.36MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   0%|                     | 27.6M/13.8G [00:03<17:17, 13.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   1%|           | 135M/13.8G [00:03<03:23, 67.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   0%|                     | 50.1M/13.8G [00:03<08:10, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   1%|▏          | 160M/13.8G [00:03<02:46, 81.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   0%|    | 19.4M/4.79G [00:03<10:43, 7.41MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 4.30M/4.80G [00:04<59:58, 1.33MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   1%|▏          | 189M/13.8G [00:04<03:17, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   1%|    | 29.8M/4.79G [00:04<06:47, 11.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   1%|                     | 76.3M/13.8G [00:04<07:24, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:   8%|▍    | 338M/4.17G [00:04<00:45, 83.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   1%|    | 53.2M/4.79G [00:04<03:34, 22.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  11%|▋     | 472M/4.17G [00:04<00:29, 126MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|   | 4.56M/4.80G [00:05<1:37:44, 817kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  15%|▊     | 606M/4.17G [00:05<00:21, 167MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   2%|▏          | 264M/13.8G [00:05<03:35, 62.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   1%|▏                    | 99.8M/13.8G [00:05<09:08, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  18%|█     | 741M/4.17G [00:05<00:15, 228MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   1%|▏                     | 107M/13.8G [00:05<08:22, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  19%|█▏    | 808M/4.17G [00:05<00:13, 254MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   2%|    | 77.3M/4.79G [00:05<03:36, 21.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   1%|▏                     | 131M/13.8G [00:05<05:24, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|   | 4.76M/4.80G [00:06<2:19:31, 573kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   2%|▎          | 332M/13.8G [00:06<03:39, 61.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  23%|█▎    | 942M/4.17G [00:06<00:16, 194MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   2%|    | 80.1M/4.79G [00:06<05:16, 14.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   1%|▎                     | 180M/13.8G [00:06<05:08, 43.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 7.58M/4.80G [00:07<53:33, 1.49MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   2%|▎          | 340M/13.8G [00:07<04:53, 45.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   2%|▌                     | 314M/13.8G [00:07<02:30, 89.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   3%|▎          | 407M/13.8G [00:07<03:02, 73.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   3%|▋                      | 448M/13.8G [00:07<01:21, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   2%|     | 104M/4.79G [00:08<04:57, 15.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   4%|▊                      | 515M/13.8G [00:08<01:19, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   2%|     | 107M/4.79G [00:08<04:52, 16.0MB/s]\u001b[A\n",
      "model-00000-of-00002.safetensors:   2%|     | 109M/4.79G [00:09<07:08, 10.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   4%|█                      | 610M/13.8G [00:09<01:47, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   3%|▍          | 475M/13.8G [00:11<07:05, 31.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  24%|▉   | 1.01G/4.17G [00:16<01:51, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|   | 10.7M/4.80G [00:17<2:49:50, 470kB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   2%|     | 118M/4.79G [00:19<32:35, 2.39MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   5%|█                      | 633M/13.8G [00:19<01:47, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  32%|█▎  | 1.33G/4.17G [00:21<01:05, 43.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|   | 13.6M/4.80G [00:21<2:17:31, 580kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   4%|▍          | 556M/13.8G [00:21<14:37, 15.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  41%|█▌  | 1.69G/4.17G [00:21<00:30, 80.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   5%|█                     | 700M/13.8G [00:21<10:55, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   5%|▍          | 623M/13.8G [00:22<10:49, 20.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   6%|█▏                    | 768M/13.8G [00:22<08:54, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   5%|▌          | 707M/13.8G [00:23<07:29, 29.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   8%|█▌                   | 1.04G/13.8G [00:23<03:50, 55.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   5%|▌          | 740M/13.8G [00:23<06:49, 31.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   3%|▏    | 140M/4.79G [00:23<23:00, 3.37MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  45%|█▊  | 1.89G/4.17G [00:23<00:27, 84.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   9%|█▊                   | 1.19G/13.8G [00:23<02:41, 78.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  47%|█▊  | 1.95G/4.17G [00:23<00:24, 91.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:   9%|█▉                   | 1.29G/13.8G [00:24<02:09, 96.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   5%|▌          | 748M/13.8G [00:24<07:27, 29.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   5%|▏    | 218M/4.79G [00:24<06:56, 11.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  50%|██▍  | 2.08G/4.17G [00:24<00:20, 104MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  10%|██                   | 1.35G/13.8G [00:25<02:19, 88.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  51%|██▌  | 2.15G/4.17G [00:25<00:19, 106MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  11%|██▎                   | 1.46G/13.8G [00:25<01:47, 114MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   6%|▎    | 285M/4.79G [00:25<03:58, 18.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   6%|▋          | 882M/13.8G [00:25<04:12, 50.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   7%|▎    | 315M/4.79G [00:25<03:09, 23.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|   | 13.8M/4.80G [00:25<3:19:38, 399kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|   | 14.4M/4.80G [00:26<3:02:17, 437kB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   7%|▎    | 324M/4.79G [00:26<03:22, 22.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   6%|▋          | 891M/13.8G [00:26<05:09, 41.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   7%|▎    | 347M/4.79G [00:27<03:27, 21.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   7%|▊          | 950M/13.8G [00:27<04:57, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|   | 14.6M/4.80G [00:27<3:33:36, 373kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  11%|██▎                  | 1.50G/13.8G [00:27<03:14, 63.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   8%|▊         | 1.09G/13.8G [00:27<02:28, 85.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   7%|▎    | 359M/4.79G [00:27<03:22, 21.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|   | 15.3M/4.80G [00:27<2:44:26, 485kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   8%|▊         | 1.16G/13.8G [00:28<02:20, 89.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|   | 15.6M/4.80G [00:28<2:45:12, 483kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  11%|██▎                  | 1.54G/13.8G [00:28<03:27, 58.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   8%|▍    | 372M/4.79G [00:28<03:40, 20.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  11%|██▍                  | 1.57G/13.8G [00:29<03:51, 52.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:   9%|▉         | 1.23G/13.8G [00:29<02:51, 72.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   8%|▍    | 377M/4.79G [00:30<06:00, 12.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|    | 25.6M/4.80G [00:30<37:33, 2.12MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  12%|██▌                  | 1.70G/13.8G [00:30<02:46, 72.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  10%|▉         | 1.34G/13.8G [00:30<02:21, 87.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   8%|▍    | 386M/4.79G [00:31<05:21, 13.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  13%|██▋                  | 1.73G/13.8G [00:31<03:12, 62.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  10%|█         | 1.41G/13.8G [00:31<02:25, 85.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  13%|██▊                  | 1.81G/13.8G [00:32<02:56, 67.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  11%|█         | 1.54G/13.8G [00:33<02:40, 76.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  14%|██▉                  | 1.90G/13.8G [00:33<02:43, 72.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  14%|██▉                  | 1.91G/13.8G [00:34<03:44, 52.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  13%|█▎        | 1.74G/13.8G [00:35<02:15, 88.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  14%|██▉                  | 1.94G/13.8G [00:35<03:59, 49.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   9%|▍    | 410M/4.79G [00:35<08:55, 8.18MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|   | 26.0M/4.80G [00:35<1:21:17, 979kB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   9%|▍    | 427M/4.79G [00:36<07:42, 9.43MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  14%|█▌         | 1.95G/13.8G [00:36<01:48, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|   | 26.2M/4.80G [00:36<1:33:31, 850kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  15%|█▌         | 2.01G/13.8G [00:37<01:52, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:   9%|▍    | 441M/4.79G [00:38<08:03, 8.99MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  15%|█▌        | 2.08G/13.8G [00:38<02:11, 88.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  14%|███                  | 1.99G/13.8G [00:38<06:35, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|   | 26.5M/4.80G [00:38<2:02:41, 648kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  16%|█▊         | 2.21G/13.8G [00:38<01:32, 125MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  15%|███                  | 2.00G/13.8G [00:39<06:42, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  17%|█▊         | 2.28G/13.8G [00:39<01:36, 119MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  11%|▌    | 508M/4.79G [00:39<03:41, 19.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  52%|██▌  | 2.16G/4.17G [00:39<00:18, 106MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  15%|███                  | 2.01G/13.8G [00:40<08:51, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  52%|██  | 2.16G/4.17G [00:40<01:51, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  18%|█▉         | 2.42G/13.8G [00:40<01:23, 136MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  11%|▌    | 511M/4.79G [00:40<04:12, 16.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|   | 26.7M/4.80G [00:40<2:31:04, 526kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|  | 29.6M/4.80G [00:40<1:11:09, 1.12MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  11%|▌    | 513M/4.79G [00:40<04:18, 16.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  15%|███                  | 2.03G/13.8G [00:41<08:38, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  18%|█▉         | 2.48G/13.8G [00:41<01:44, 108MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  52%|██  | 2.16G/4.17G [00:41<02:02, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  19%|██         | 2.62G/13.8G [00:42<01:21, 136MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  15%|███▏                 | 2.05G/13.8G [00:42<10:03, 19.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  20%|██▏        | 2.69G/13.8G [00:43<01:40, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|  | 32.5M/4.80G [00:43<1:12:44, 1.09MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  11%|▌    | 522M/4.79G [00:43<07:30, 9.47MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  21%|██▎        | 2.82G/13.8G [00:43<01:21, 134MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|    | 56.0M/4.80G [00:44<14:14, 5.55MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  21%|██▎        | 2.94G/13.8G [00:44<01:24, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  12%|▌    | 567M/4.79G [00:45<05:09, 13.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  22%|██▍        | 3.01G/13.8G [00:45<01:29, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  16%|███▎                 | 2.14G/13.8G [00:45<07:29, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  23%|██▌        | 3.14G/13.8G [00:46<01:30, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  54%|██▏ | 2.23G/4.17G [00:47<02:13, 14.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  23%|██▌        | 3.21G/13.8G [00:47<01:36, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  12%|▌    | 573M/4.79G [00:47<07:01, 10.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  16%|███▎                 | 2.14G/13.8G [00:47<10:46, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|    | 66.5M/4.80G [00:47<18:43, 4.21MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  12%|▌    | 595M/4.79G [00:48<05:29, 12.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  16%|███▎                 | 2.17G/13.8G [00:48<09:29, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  24%|██▍       | 3.28G/13.8G [00:49<02:17, 76.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  25%|██▊        | 3.48G/13.8G [00:50<01:30, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  54%|██▏ | 2.26G/4.17G [00:50<02:20, 13.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  12%|▌    | 596M/4.79G [00:50<09:12, 7.59MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  26%|██▌       | 3.54G/13.8G [00:51<02:00, 84.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  13%|▋    | 599M/4.79G [00:51<10:04, 6.94MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  16%|███▎                 | 2.18G/13.8G [00:51<17:08, 11.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  27%|███        | 3.75G/13.8G [00:52<01:11, 141MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  13%|▋    | 600M/4.79G [00:52<10:30, 6.65MB/s]\u001b[A\n",
      "model-00000-of-00002.safetensors:  13%|▋    | 624M/4.79G [00:52<05:08, 13.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  16%|███▎                 | 2.18G/13.8G [00:53<20:40, 9.32MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  28%|██▊       | 3.82G/13.8G [00:54<01:48, 91.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  13%|▋    | 635M/4.79G [00:54<06:52, 10.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  16%|███▍                 | 2.25G/13.8G [00:54<09:38, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|    | 70.0M/4.80G [00:54<39:05, 2.02MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 137M/4.80G [00:55<08:38, 8.99MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  29%|██▊       | 3.96G/13.8G [00:55<01:51, 87.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  14%|▋    | 659M/4.79G [00:55<05:31, 12.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  16%|███▍                 | 2.26G/13.8G [00:55<11:44, 16.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  16%|███▍                 | 2.26G/13.8G [00:55<12:08, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  14%|▋    | 669M/4.79G [00:56<05:01, 13.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  17%|███▍                 | 2.27G/13.8G [00:57<14:20, 13.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  17%|███▍                 | 2.28G/13.8G [00:57<13:24, 14.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  14%|▋    | 673M/4.79G [00:58<09:21, 7.33MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  17%|███▍                 | 2.29G/13.8G [00:58<17:32, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  15%|▋    | 696M/4.79G [00:59<06:26, 10.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  29%|██▉       | 4.04G/13.8G [01:00<03:24, 47.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  17%|███▌                 | 2.29G/13.8G [01:00<23:25, 8.15MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  33%|███▋       | 4.57G/13.8G [01:00<01:07, 137MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  15%|▋    | 700M/4.79G [01:00<07:02, 9.68MB/s]\u001b[A\n",
      "model-00000-of-00002.safetensors:  15%|▋    | 705M/4.79G [01:00<06:24, 10.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  17%|███▌                 | 2.31G/13.8G [01:01<16:22, 11.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 161M/4.80G [01:01<11:11, 6.91MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  34%|███▋       | 4.63G/13.8G [01:01<01:09, 131MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  15%|▋    | 708M/4.79G [01:01<06:32, 10.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 188M/4.80G [01:01<08:16, 9.29MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  15%|▋    | 711M/4.79G [01:01<08:04, 8.43MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  34%|███▊       | 4.70G/13.8G [01:01<01:13, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  17%|███▌                 | 2.32G/13.8G [01:02<16:55, 11.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  15%|▋    | 716M/4.79G [01:02<07:29, 9.07MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5%|▏    | 236M/4.80G [01:02<04:47, 15.9MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  15%|▋    | 719M/4.79G [01:02<08:27, 8.02MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  17%|███▌                 | 2.33G/13.8G [01:03<15:21, 12.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5%|▎    | 247M/4.80G [01:03<05:01, 15.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  35%|███▊       | 4.76G/13.8G [01:03<01:29, 101MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  16%|▊    | 786M/4.79G [01:03<01:37, 41.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  17%|███▌                 | 2.34G/13.8G [01:03<17:20, 11.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  56%|██▏ | 2.32G/4.17G [01:03<03:38, 8.45MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  17%|███▌                 | 2.34G/13.8G [01:04<20:20, 9.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  57%|██▎ | 2.39G/4.17G [01:04<02:27, 12.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6%|▎    | 271M/4.80G [01:04<04:59, 15.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  17%|███▌                 | 2.37G/13.8G [01:04<09:54, 19.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  18%|▉    | 856M/4.79G [01:05<01:50, 35.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  17%|███▌                 | 2.37G/13.8G [01:05<11:59, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6%|▎    | 276M/4.80G [01:05<05:34, 13.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6%|▎    | 299M/4.80G [01:05<03:51, 19.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  17%|███▋                 | 2.40G/13.8G [01:05<06:31, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 323M/4.80G [01:06<02:57, 25.2MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  20%|▉    | 939M/4.79G [01:06<01:15, 50.9MB/s]\u001b[A\n",
      "model-00000-of-00002.safetensors:  21%|▊   | 1.01G/4.79G [01:06<00:55, 67.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  58%|██▎ | 2.40G/4.17G [01:06<02:43, 10.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  18%|███▋                 | 2.41G/13.8G [01:07<10:34, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  18%|███▋                 | 2.45G/13.8G [01:07<05:42, 33.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  58%|██▎ | 2.41G/4.17G [01:07<02:38, 11.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  18%|███▊                 | 2.50G/13.8G [01:07<03:08, 59.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 329M/4.80G [01:07<04:26, 16.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 334M/4.80G [01:07<04:05, 18.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  18%|███▊                 | 2.52G/13.8G [01:07<02:45, 67.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  58%|██▎ | 2.44G/4.17G [01:08<02:09, 13.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  18%|███▊                 | 2.54G/13.8G [01:08<03:22, 55.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  21%|▊   | 1.03G/4.79G [01:08<01:28, 42.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 359M/4.80G [01:10<05:41, 13.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  19%|████                 | 2.63G/13.8G [01:10<04:13, 43.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  59%|██▍ | 2.48G/4.17G [01:11<02:06, 13.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  20%|████                 | 2.69G/13.8G [01:11<03:20, 55.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  35%|███▌      | 4.84G/13.8G [01:11<04:30, 33.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  20%|████▏                | 2.71G/13.8G [01:11<03:07, 59.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  61%|██▍ | 2.55G/4.17G [01:11<01:11, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  20%|████▏                | 2.74G/13.8G [01:11<02:50, 64.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  22%|▉   | 1.07G/4.79G [01:11<02:22, 26.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  20%|████▏                | 2.75G/13.8G [01:11<02:48, 65.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  63%|██▌ | 2.62G/4.17G [01:12<00:45, 34.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  20%|████▏                | 2.77G/13.8G [01:12<02:36, 70.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  20%|████▎                | 2.79G/13.8G [01:12<02:51, 63.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  20%|████▎                | 2.81G/13.8G [01:12<02:21, 77.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 363M/4.80G [01:12<09:28, 7.81MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  21%|████▎                | 2.85G/13.8G [01:13<02:20, 77.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 386M/4.80G [01:13<06:02, 12.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  21%|████▋                 | 2.90G/13.8G [01:13<01:35, 114MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  21%|████▋                 | 2.92G/13.8G [01:13<01:40, 107MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  64%|██▌ | 2.68G/4.17G [01:14<00:47, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  24%|▉   | 1.15G/4.79G [01:15<02:36, 23.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  21%|████▍                | 2.94G/13.8G [01:15<05:12, 34.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  25%|█   | 1.21G/4.79G [01:16<01:59, 29.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  66%|██▋ | 2.76G/4.17G [01:16<00:41, 34.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  21%|████▌                | 2.95G/13.8G [01:16<06:44, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  27%|█   | 1.28G/4.79G [01:17<01:32, 37.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  22%|████▌                | 3.02G/13.8G [01:17<03:51, 46.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  27%|█   | 1.29G/4.79G [01:17<01:30, 38.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  22%|████▋                | 3.04G/13.8G [01:17<03:19, 53.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 390M/4.80G [01:17<12:41, 5.79MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  36%|███▌      | 4.91G/13.8G [01:18<06:27, 22.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 414M/4.80G [01:18<07:52, 9.27MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  22%|████▋                | 3.07G/13.8G [01:17<03:34, 49.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10%|▌    | 482M/4.80G [01:19<03:45, 19.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  36%|███▌      | 4.98G/13.8G [01:20<06:00, 24.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  22%|████▋                | 3.09G/13.8G [01:20<06:57, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  36%|███▋      | 5.02G/13.8G [01:20<05:15, 27.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  23%|████▋                | 3.10G/13.8G [01:21<08:08, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  68%|██▋ | 2.82G/4.17G [01:21<00:55, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  68%|██▋ | 2.85G/4.17G [01:21<00:48, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  23%|████▊                | 3.13G/13.8G [01:21<06:45, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  28%|█▏  | 1.35G/4.79G [01:21<02:28, 23.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  23%|████▊                | 3.14G/13.8G [01:22<07:48, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  30%|█▏  | 1.42G/4.79G [01:22<01:46, 31.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  70%|██▊ | 2.92G/4.17G [01:22<00:38, 32.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  23%|████▊                | 3.15G/13.8G [01:22<07:31, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|▌    | 552M/4.80G [01:24<04:29, 15.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  23%|████▊                | 3.16G/13.8G [01:24<13:03, 13.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  72%|██▊ | 2.98G/4.17G [01:25<00:41, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  31%|█▏  | 1.48G/4.79G [01:25<01:56, 28.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  37%|███▋      | 5.09G/13.8G [01:25<06:36, 21.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  23%|████▊                | 3.16G/13.8G [01:25<14:41, 12.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  72%|██▉ | 3.01G/4.17G [01:25<00:36, 32.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  23%|████▊                | 3.17G/13.8G [01:25<13:49, 12.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12%|▌    | 555M/4.80G [01:25<05:02, 14.0MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  32%|█▎  | 1.55G/4.79G [01:25<01:21, 39.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  37%|███▋      | 5.16G/13.8G [01:25<04:54, 29.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  23%|████▊                | 3.18G/13.8G [01:25<10:55, 16.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  72%|██▉ | 3.02G/4.17G [01:25<00:34, 33.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  23%|████▉                | 3.21G/13.8G [01:25<04:55, 35.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12%|▌    | 567M/4.80G [01:25<04:27, 15.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  23%|████▉                | 3.22G/13.8G [01:26<05:24, 32.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  74%|██▉ | 3.08G/4.17G [01:26<00:23, 45.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12%|▌    | 591M/4.80G [01:26<03:50, 18.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  24%|████▉                | 3.25G/13.8G [01:26<03:43, 46.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  38%|███▊      | 5.18G/13.8G [01:26<05:09, 27.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  75%|██▉ | 3.12G/4.17G [01:26<00:19, 54.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  13%|▋    | 615M/4.80G [01:27<02:53, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  24%|████▉                | 3.26G/13.8G [01:27<03:50, 45.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  13%|▋    | 624M/4.80G [01:28<03:58, 17.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  24%|████▉                | 3.27G/13.8G [01:28<10:04, 17.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  38%|███▊      | 5.24G/13.8G [01:28<04:49, 29.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  13%|▋    | 636M/4.80G [01:29<03:56, 17.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  24%|█████                | 3.35G/13.8G [01:29<03:28, 50.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  39%|███▊      | 5.31G/13.8G [01:30<04:01, 34.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  76%|███ | 3.18G/4.17G [01:31<00:37, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  34%|█▎  | 1.62G/4.79G [01:31<02:12, 24.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  24%|█████▏               | 3.36G/13.8G [01:31<06:45, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  25%|█████▏               | 3.38G/13.8G [01:31<06:08, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  78%|███ | 3.25G/4.17G [01:32<00:29, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  39%|███▉      | 5.38G/13.8G [01:32<04:20, 32.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  25%|█████▏               | 3.40G/13.8G [01:32<06:15, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  25%|█████▏               | 3.42G/13.8G [01:32<05:33, 31.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  13%|▋    | 641M/4.80G [01:33<09:32, 7.26MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  25%|█████▎               | 3.47G/13.8G [01:33<04:15, 40.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  79%|███▏| 3.31G/4.17G [01:33<00:23, 36.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  14%|▋    | 665M/4.80G [01:33<06:22, 10.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  40%|███▉      | 5.45G/13.8G [01:34<04:05, 33.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  35%|█▍  | 1.69G/4.79G [01:34<02:23, 21.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  25%|█████▎               | 3.48G/13.8G [01:34<05:56, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  80%|███▏| 3.34G/4.17G [01:34<00:25, 33.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  26%|█████▍               | 3.52G/13.8G [01:35<03:46, 45.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  14%|▋    | 669M/4.80G [01:36<09:31, 7.23MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  26%|█████▍               | 3.54G/13.8G [01:36<05:52, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  40%|████      | 5.52G/13.8G [01:37<04:39, 29.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  16%|▊    | 778M/4.80G [01:37<02:30, 26.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  26%|█████▍               | 3.54G/13.8G [01:37<08:03, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  41%|████      | 5.58G/13.8G [01:37<03:32, 38.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  36%|█▍  | 1.71G/4.79G [01:37<03:01, 17.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  80%|███▏| 3.34G/4.17G [01:38<00:46, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  26%|█████▍               | 3.55G/13.8G [01:38<09:25, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  17%|▊    | 831M/4.80G [01:38<02:03, 32.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  26%|█████▍               | 3.56G/13.8G [01:38<10:20, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  41%|████      | 5.65G/13.8G [01:38<03:05, 43.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  18%|▉    | 861M/4.80G [01:38<01:51, 35.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  26%|█████▍               | 3.58G/13.8G [01:38<07:03, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  26%|█████▍               | 3.60G/13.8G [01:39<04:34, 37.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  80%|███▏| 3.35G/4.17G [01:39<00:54, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  26%|█████▌               | 3.62G/13.8G [01:39<03:08, 53.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  41%|████      | 5.66G/13.8G [01:39<03:13, 41.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  27%|█████▌               | 3.66G/13.8G [01:39<02:13, 75.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  18%|▉    | 886M/4.80G [01:39<01:56, 33.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  27%|█████▌               | 3.67G/13.8G [01:40<03:05, 54.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  36%|█▍  | 1.72G/4.79G [01:40<03:26, 14.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  27%|█████▋               | 3.69G/13.8G [01:40<03:49, 43.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  82%|███▎| 3.41G/4.17G [01:40<00:32, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  37%|█▍  | 1.79G/4.79G [01:41<02:32, 19.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  82%|███▎| 3.44G/4.17G [01:41<00:32, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  27%|█████▋               | 3.76G/13.8G [01:42<03:44, 44.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  39%|█▌  | 1.86G/4.79G [01:42<01:39, 29.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  27%|█████▊               | 3.77G/13.8G [01:42<04:35, 36.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  42%|████▏     | 5.73G/13.8G [01:42<04:38, 28.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  27%|█████▊               | 3.78G/13.8G [01:43<04:44, 35.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  40%|█▌  | 1.92G/4.79G [01:43<01:20, 35.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  83%|███▎| 3.45G/4.17G [01:43<00:44, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  28%|█████▊               | 3.79G/13.8G [01:43<05:34, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19%|▉    | 891M/4.80G [01:43<04:51, 13.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  28%|█████▉               | 3.89G/13.8G [01:44<02:37, 62.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  42%|█▋  | 1.99G/4.79G [01:45<01:21, 34.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  84%|███▎| 3.51G/4.17G [01:45<00:27, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  28%|█████▉               | 3.91G/13.8G [01:45<03:26, 47.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19%|▉    | 894M/4.80G [01:45<06:18, 10.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  29%|██████               | 3.93G/13.8G [01:45<02:53, 56.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  42%|████▏     | 5.74G/13.8G [01:45<06:47, 19.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  85%|███▍| 3.53G/4.17G [01:45<00:25, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  29%|██████               | 3.96G/13.8G [01:45<02:30, 65.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  29%|██████               | 3.97G/13.8G [01:46<02:25, 67.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  29%|██████               | 3.98G/13.8G [01:46<02:47, 58.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  85%|███▍| 3.55G/4.17G [01:46<00:23, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  30%|██████▍               | 4.06G/13.8G [01:46<01:17, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19%|▉    | 909M/4.80G [01:46<05:48, 11.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19%|▉    | 922M/4.80G [01:47<04:55, 13.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  30%|██████▏              | 4.09G/13.8G [01:47<01:40, 96.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  86%|███▍| 3.59G/4.17G [01:47<00:18, 30.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19%|▉    | 933M/4.80G [01:48<05:14, 12.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  88%|███▌| 3.66G/4.17G [01:48<00:10, 48.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  88%|███▌| 3.67G/4.17G [01:48<00:11, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  30%|██████▎              | 4.15G/13.8G [01:48<02:39, 60.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  42%|████▏     | 5.75G/13.8G [01:48<10:24, 12.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  89%|███▌| 3.72G/4.17G [01:49<00:10, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  42%|████▏     | 5.82G/13.8G [01:49<06:14, 21.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  31%|██████▍              | 4.24G/13.8G [01:49<02:23, 66.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  20%|▉    | 956M/4.80G [01:50<05:16, 12.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  31%|██████▌              | 4.26G/13.8G [01:50<02:14, 70.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  42%|█▋  | 2.03G/4.79G [01:50<02:20, 19.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  42%|████▏     | 5.82G/13.8G [01:50<07:25, 17.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  31%|██████▌              | 4.28G/13.8G [01:50<02:50, 55.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  91%|███▋| 3.78G/4.17G [01:51<00:09, 39.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  20%|█    | 980M/4.80G [01:51<05:04, 12.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  31%|██████▌              | 4.29G/13.8G [01:52<05:06, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  91%|███▋| 3.81G/4.17G [01:52<00:09, 36.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21%|▊   | 1.00G/4.80G [01:52<04:02, 15.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  32%|██████▋              | 4.42G/13.8G [01:52<01:57, 79.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  43%|█▋  | 2.04G/4.79G [01:52<02:47, 16.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21%|▊   | 1.02G/4.80G [01:53<04:10, 15.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  42%|████▏     | 5.85G/13.8G [01:53<09:18, 14.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  32%|██████▊              | 4.45G/13.8G [01:53<02:35, 59.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  33%|██████▊              | 4.47G/13.8G [01:53<02:17, 67.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  33%|██████▊              | 4.50G/13.8G [01:54<02:35, 59.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  92%|███▋| 3.85G/4.17G [01:54<00:10, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21%|▊   | 1.02G/4.80G [01:54<05:15, 12.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  93%|███▋| 3.88G/4.17G [01:54<00:08, 35.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22%|▊   | 1.04G/4.80G [01:54<03:13, 19.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  43%|████▎     | 5.91G/13.8G [01:55<06:13, 21.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  94%|███▊| 3.92G/4.17G [01:55<00:06, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  33%|██████▉              | 4.52G/13.8G [01:55<03:31, 43.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  43%|█▋  | 2.07G/4.79G [01:55<03:14, 14.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  33%|██████▉              | 4.54G/13.8G [01:55<03:21, 45.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  43%|████▎     | 5.94G/13.8G [01:55<05:35, 23.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  33%|██████▉              | 4.56G/13.8G [01:55<02:49, 54.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  44%|████▎     | 6.01G/13.8G [01:56<03:58, 32.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  95%|███▊| 3.97G/4.17G [01:57<00:05, 34.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  45%|█▊  | 2.14G/4.79G [01:57<02:29, 17.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  33%|██████▉              | 4.57G/13.8G [01:57<06:21, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22%|▉   | 1.05G/4.80G [01:58<07:09, 8.73MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  97%|███▊| 4.04G/4.17G [01:58<00:03, 37.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors:  98%|███▉| 4.10G/4.17G [01:59<00:01, 50.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  45%|█▊  | 2.16G/4.79G [01:59<02:34, 17.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  33%|██████▉              | 4.58G/13.8G [01:59<09:41, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  33%|███████              | 4.59G/13.8G [01:59<08:38, 17.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  34%|███████              | 4.61G/13.8G [01:59<05:45, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  34%|███████              | 4.64G/13.8G [02:00<05:06, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  44%|████▍     | 6.06G/13.8G [02:00<05:29, 23.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  46%|█▊  | 2.23G/4.79G [02:00<01:45, 24.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors: 100%|████| 4.17G/4.17G [02:01<00:00, 44.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00002.safetensors: 100%|████| 4.17G/4.17G [02:01<00:00, 34.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/model-00002-of-00002.safetensors\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  34%|███████▏             | 4.67G/13.8G [02:01<03:46, 40.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  47%|█▊  | 2.24G/4.79G [02:01<01:45, 24.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  34%|███████▏             | 4.71G/13.8G [02:01<02:16, 66.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  34%|███████▏             | 4.73G/13.8G [02:01<02:45, 54.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22%|▉   | 1.07G/4.80G [02:02<08:45, 7.09MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  35%|███████▎             | 4.80G/13.8G [02:02<01:45, 84.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  48%|█▉  | 2.31G/4.79G [02:02<01:19, 31.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  44%|████▍     | 6.07G/13.8G [02:02<07:29, 17.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  35%|███████▎             | 4.82G/13.8G [02:02<01:47, 82.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  35%|███████▍             | 4.83G/13.8G [02:02<01:50, 81.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  35%|███████▍             | 4.86G/13.8G [02:03<01:39, 89.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  45%|████▍     | 6.13G/13.8G [02:04<05:50, 21.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  35%|███████▍             | 4.87G/13.8G [02:04<04:57, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  45%|████▌     | 6.20G/13.8G [02:04<03:37, 34.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  36%|███████▌             | 4.93G/13.8G [02:04<02:19, 63.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24%|▉   | 1.14G/4.80G [02:05<04:57, 12.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  36%|███████▌             | 4.96G/13.8G [02:05<02:29, 58.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  36%|███████▌             | 4.98G/13.8G [02:05<02:05, 69.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24%|▉   | 1.15G/4.80G [02:05<04:53, 12.4MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  50%|█▉  | 2.38G/4.79G [02:06<01:36, 24.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  36%|███████▋             | 5.01G/13.8G [02:06<03:11, 45.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  51%|██  | 2.45G/4.79G [02:06<01:05, 36.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  37%|███████▋             | 5.03G/13.8G [02:06<02:34, 56.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  37%|███████▋             | 5.05G/13.8G [02:07<02:18, 62.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  37%|███████▊             | 5.08G/13.8G [02:07<02:43, 53.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24%|▉   | 1.15G/4.80G [02:07<06:55, 8.79MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  46%|████▌     | 6.27G/13.8G [02:07<04:04, 30.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  37%|███████▊             | 5.09G/13.8G [02:07<02:19, 61.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  37%|███████▊             | 5.10G/13.8G [02:08<03:04, 46.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  52%|██  | 2.51G/4.79G [02:08<01:00, 37.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24%|▉   | 1.15G/4.80G [02:08<07:41, 7.91MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24%|▉   | 1.15G/4.80G [02:08<07:32, 8.07MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  37%|███████▊             | 5.12G/13.8G [02:08<02:46, 51.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  37%|███████▊             | 5.14G/13.8G [02:08<02:07, 67.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  25%|█   | 1.22G/4.80G [02:10<02:56, 20.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  46%|████▌     | 6.34G/13.8G [02:10<04:38, 26.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  27%|█   | 1.29G/4.80G [02:10<01:38, 35.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  37%|███████▊             | 5.15G/13.8G [02:11<07:55, 18.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  46%|████▌     | 6.36G/13.8G [02:11<04:24, 28.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  38%|███████▉             | 5.22G/13.8G [02:11<04:04, 34.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  47%|████▋     | 6.42G/13.8G [02:11<03:10, 38.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  53%|██  | 2.54G/4.79G [02:12<01:41, 22.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  38%|████████             | 5.24G/13.8G [02:12<03:31, 40.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  38%|████████             | 5.26G/13.8G [02:12<03:05, 45.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  54%|██▏ | 2.56G/4.79G [02:12<01:29, 24.9MB/s]\u001b[A\n",
      "model-00000-of-00002.safetensors:  54%|██▏ | 2.61G/4.79G [02:12<01:04, 34.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  38%|████████             | 5.27G/13.8G [02:12<03:19, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  27%|█   | 1.31G/4.80G [02:12<02:25, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  38%|████████             | 5.28G/13.8G [02:12<03:12, 44.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  38%|████████             | 5.29G/13.8G [02:13<02:46, 50.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  39%|████████             | 5.30G/13.8G [02:13<02:34, 54.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  39%|████████▏            | 5.33G/13.8G [02:13<01:40, 84.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  27%|█   | 1.32G/4.80G [02:14<03:02, 19.1MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  56%|██▏ | 2.68G/4.79G [02:14<00:54, 38.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  39%|████████▏            | 5.34G/13.8G [02:14<03:32, 39.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  29%|█▏  | 1.38G/4.80G [02:15<01:50, 30.8MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  57%|██▎ | 2.73G/4.79G [02:15<00:48, 42.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  39%|████████▏            | 5.36G/13.8G [02:15<05:33, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  58%|██▎ | 2.80G/4.79G [02:15<00:37, 52.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  39%|████████▏            | 5.36G/13.8G [02:15<06:43, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  39%|████████▏            | 5.38G/13.8G [02:16<04:42, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  39%|████████▏            | 5.40G/13.8G [02:16<03:40, 37.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  59%|██▍ | 2.85G/4.79G [02:17<00:39, 48.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  30%|█▏  | 1.45G/4.80G [02:17<01:42, 32.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  39%|████████▎            | 5.42G/13.8G [02:17<04:57, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  47%|████▋     | 6.49G/13.8G [02:17<05:46, 21.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  40%|████████▎            | 5.43G/13.8G [02:17<05:08, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  40%|████████▎            | 5.45G/13.8G [02:18<05:21, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  32%|█▎  | 1.52G/4.80G [02:18<01:29, 36.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  40%|████████▎            | 5.46G/13.8G [02:18<04:03, 34.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  40%|████████▎            | 5.48G/13.8G [02:18<03:11, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  40%|████████▍            | 5.49G/13.8G [02:19<02:48, 49.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  61%|██▍ | 2.91G/4.79G [02:19<00:47, 39.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  40%|████████▍            | 5.51G/13.8G [02:19<02:38, 52.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  40%|████████▍            | 5.53G/13.8G [02:19<01:41, 81.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  32%|█▎  | 1.52G/4.80G [02:19<01:47, 30.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  40%|████████▍            | 5.56G/13.8G [02:19<01:25, 96.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  32%|█▎  | 1.53G/4.80G [02:19<01:46, 30.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  41%|████████▌            | 5.57G/13.8G [02:19<01:22, 99.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  61%|██▍ | 2.93G/4.79G [02:19<00:50, 37.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  41%|████████▌            | 5.60G/13.8G [02:20<01:36, 84.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  41%|████████▌            | 5.62G/13.8G [02:20<01:33, 86.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  41%|████████▌            | 5.64G/13.8G [02:21<03:28, 38.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  33%|█▎  | 1.60G/4.80G [02:21<01:34, 33.9MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  62%|██▍ | 2.99G/4.79G [02:21<00:45, 39.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  47%|████▋     | 6.50G/13.8G [02:21<08:24, 14.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  41%|████████▌            | 5.65G/13.8G [02:21<03:42, 36.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  47%|████▋     | 6.51G/13.8G [02:21<08:02, 15.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35%|█▍  | 1.66G/4.80G [02:23<01:28, 35.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  41%|████████▋            | 5.67G/13.8G [02:23<05:33, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  48%|████▊     | 6.58G/13.8G [02:23<05:28, 21.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  41%|████████▋            | 5.68G/13.8G [02:23<06:15, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  48%|████▊     | 6.64G/13.8G [02:24<03:51, 30.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  64%|██▌ | 3.06G/4.79G [02:24<00:52, 33.1MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35%|█▍  | 1.68G/4.80G [02:24<01:37, 32.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  41%|████████▋            | 5.69G/13.8G [02:24<08:48, 15.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  65%|██▌ | 3.10G/4.79G [02:24<00:47, 35.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  49%|████▉     | 6.71G/13.8G [02:24<03:00, 39.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  41%|████████▋            | 5.70G/13.8G [02:25<05:41, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  42%|████████▋            | 5.72G/13.8G [02:25<03:56, 34.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35%|█▍  | 1.69G/4.80G [02:25<02:24, 21.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  49%|████▉     | 6.78G/13.8G [02:25<02:29, 46.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  42%|████████▊            | 5.74G/13.8G [02:25<04:48, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35%|█▍  | 1.69G/4.80G [02:25<02:21, 22.0MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  66%|██▋ | 3.17G/4.79G [02:25<00:37, 42.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  42%|████████▊            | 5.74G/13.8G [02:26<04:23, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  42%|████████▊            | 5.76G/13.8G [02:26<05:35, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  68%|██▋ | 3.24G/4.79G [02:26<00:32, 48.4MB/s]\u001b[A\n",
      "model-00000-of-00002.safetensors:  69%|██▊ | 3.31G/4.79G [02:27<00:27, 54.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  37%|█▍  | 1.76G/4.80G [02:27<01:49, 27.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  42%|████████▊            | 5.77G/13.8G [02:27<07:41, 17.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  42%|████████▊            | 5.79G/13.8G [02:28<04:49, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  42%|████████▊            | 5.81G/13.8G [02:28<03:30, 37.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  42%|████████▉            | 5.84G/13.8G [02:28<01:56, 67.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  37%|█▍  | 1.76G/4.80G [02:28<02:03, 24.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  43%|█████████            | 5.92G/13.8G [02:29<01:31, 85.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  43%|█████████            | 5.94G/13.8G [02:29<01:27, 88.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  70%|██▊ | 3.38G/4.79G [02:29<00:26, 53.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  37%|█▍  | 1.77G/4.80G [02:29<02:38, 19.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  43%|█████████            | 5.96G/13.8G [02:29<01:19, 98.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  43%|█████████▌            | 5.98G/13.8G [02:29<01:14, 105MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  44%|█████████▌            | 6.00G/13.8G [02:29<01:08, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  49%|████▉     | 6.79G/13.8G [02:29<05:36, 20.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  44%|█████████▎           | 6.07G/13.8G [02:30<01:32, 83.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  37%|█▍  | 1.77G/4.80G [02:30<04:03, 12.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  44%|█████████▎           | 6.09G/13.8G [02:30<01:25, 89.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  38%|█▌  | 1.84G/4.80G [02:31<01:43, 28.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39%|█▌  | 1.85G/4.80G [02:31<01:32, 31.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  44%|█████████▎           | 6.10G/13.8G [02:31<02:37, 48.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  72%|██▉ | 3.44G/4.79G [02:31<00:33, 39.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  45%|█████████▎           | 6.12G/13.8G [02:33<04:17, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39%|█▌  | 1.88G/4.80G [02:34<02:26, 19.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  45%|█████████▍           | 6.19G/13.8G [02:34<02:44, 46.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  73%|██▉ | 3.51G/4.79G [02:34<00:34, 36.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  49%|████▉     | 6.79G/13.8G [02:34<10:05, 11.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  50%|████▉     | 6.86G/13.8G [02:34<05:18, 21.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  45%|█████████▍           | 6.21G/13.8G [02:34<02:45, 45.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39%|█▌  | 1.88G/4.80G [02:34<02:31, 19.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  45%|█████████▍           | 6.21G/13.8G [02:35<03:43, 33.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  75%|██▉ | 3.58G/4.79G [02:35<00:29, 41.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  46%|█████████▌           | 6.28G/13.8G [02:36<02:26, 50.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  76%|███ | 3.63G/4.79G [02:36<00:25, 44.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  46%|█████████▋           | 6.31G/13.8G [02:36<02:05, 59.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39%|█▌  | 1.89G/4.80G [02:36<03:53, 12.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  40%|█▌  | 1.90G/4.80G [02:36<02:51, 16.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  46%|█████████▋           | 6.34G/13.8G [02:36<01:39, 74.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  40%|█▌  | 1.92G/4.80G [02:36<02:19, 20.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  46%|█████████▋           | 6.36G/13.8G [02:36<01:33, 78.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  77%|███ | 3.70G/4.79G [02:37<00:22, 48.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  46%|█████████▋           | 6.38G/13.8G [02:37<02:19, 52.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  46%|█████████▊           | 6.39G/13.8G [02:37<02:04, 59.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  47%|█████████▊           | 6.41G/13.8G [02:37<02:35, 47.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  41%|█▋  | 1.95G/4.80G [02:38<01:59, 23.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  47%|█████████▊           | 6.42G/13.8G [02:38<03:41, 33.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  42%|█▋  | 2.02G/4.80G [02:39<01:24, 32.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  50%|█████     | 6.93G/13.8G [02:39<06:25, 17.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  78%|███ | 3.73G/4.79G [02:39<00:32, 33.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  47%|█████████▊           | 6.43G/13.8G [02:39<04:37, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  47%|█████████▊           | 6.44G/13.8G [02:39<03:41, 33.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  47%|█████████▊           | 6.45G/13.8G [02:39<03:23, 35.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  47%|█████████▉           | 6.47G/13.8G [02:40<03:49, 31.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  51%|█████     | 7.00G/13.8G [02:40<04:41, 24.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44%|█▋  | 2.09G/4.80G [02:40<01:06, 41.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  47%|█████████▉           | 6.48G/13.8G [02:40<03:12, 37.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  51%|█████▏    | 7.07G/13.8G [02:41<03:21, 33.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  47%|█████████▉           | 6.50G/13.8G [02:41<03:14, 37.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  47%|█████████▉           | 6.50G/13.8G [02:41<03:17, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  48%|█████████▉           | 6.54G/13.8G [02:41<01:44, 68.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  48%|██████████           | 6.55G/13.8G [02:42<03:49, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  79%|███▏| 3.77G/4.79G [02:42<00:43, 23.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  52%|█████▏    | 7.15G/13.8G [02:42<02:59, 36.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  48%|██████████           | 6.56G/13.8G [02:42<03:40, 32.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  48%|██████████           | 6.59G/13.8G [02:42<02:06, 56.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  48%|██████████           | 6.62G/13.8G [02:43<01:51, 63.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  80%|███▏| 3.83G/4.79G [02:43<00:29, 32.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  49%|██████████▏          | 6.69G/13.8G [02:44<01:35, 74.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  49%|██████████▏          | 6.71G/13.8G [02:44<01:28, 79.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44%|█▋  | 2.10G/4.80G [02:44<02:29, 18.1MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  80%|███▏| 3.85G/4.79G [02:44<00:34, 27.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  49%|██████████▎          | 6.73G/13.8G [02:44<01:42, 68.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44%|█▊  | 2.10G/4.80G [02:44<02:38, 17.0MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  82%|███▎| 3.91G/4.79G [02:46<00:27, 32.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  45%|█▊  | 2.17G/4.80G [02:46<01:37, 27.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  46%|█▊  | 2.21G/4.80G [02:46<01:12, 35.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  49%|██████████▎          | 6.74G/13.8G [02:46<04:10, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  52%|█████▏    | 7.22G/13.8G [02:46<04:06, 26.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  49%|██████████▎          | 6.77G/13.8G [02:47<03:41, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  46%|█▊  | 2.23G/4.80G [02:47<01:14, 34.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  47%|█▊  | 2.25G/4.80G [02:47<01:04, 39.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  49%|██████████▎          | 6.78G/13.8G [02:47<03:25, 34.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  49%|██████████▍          | 6.80G/13.8G [02:47<02:16, 50.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  83%|███▎| 3.96G/4.79G [02:47<00:27, 30.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  50%|██████████▍          | 6.82G/13.8G [02:48<03:20, 34.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  84%|███▎| 4.03G/4.79G [02:48<00:17, 43.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  53%|█████▎    | 7.28G/13.8G [02:49<03:52, 27.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  50%|██████████▍          | 6.84G/13.8G [02:49<03:53, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  50%|██████████▍          | 6.87G/13.8G [02:49<02:49, 40.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  50%|██████████▌          | 6.88G/13.8G [02:50<03:53, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  53%|█████▎    | 7.35G/13.8G [02:50<03:13, 33.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  47%|█▉  | 2.26G/4.80G [02:50<02:26, 17.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  50%|██████████▌          | 6.89G/13.8G [02:50<03:39, 31.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  54%|█████▍    | 7.42G/13.8G [02:51<02:41, 39.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  54%|█████▍    | 7.48G/13.8G [02:51<02:06, 49.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  51%|██████████▋          | 6.97G/13.8G [02:51<02:15, 49.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  51%|██████████▋          | 7.00G/13.8G [02:51<01:45, 64.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  51%|██████████▋          | 7.01G/13.8G [02:51<01:42, 65.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  85%|███▍| 4.06G/4.79G [02:52<00:30, 23.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  49%|█▉  | 2.33G/4.80G [02:52<01:55, 21.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  54%|█████▍    | 7.49G/13.8G [02:52<02:50, 36.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  51%|██████████▋          | 7.03G/13.8G [02:52<02:51, 39.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  51%|██████████▊          | 7.04G/13.8G [02:53<02:19, 48.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  51%|██████████▊          | 7.06G/13.8G [02:53<01:57, 56.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  49%|█▉  | 2.37G/4.80G [02:53<01:39, 24.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  51%|██████████▊          | 7.08G/13.8G [02:53<02:29, 44.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  52%|██████████▊          | 7.09G/13.8G [02:54<03:46, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  86%|███▍| 4.12G/4.79G [02:54<00:28, 23.4MB/s]\u001b[A\n",
      "model-00000-of-00002.safetensors:  87%|███▍| 4.19G/4.79G [02:55<00:17, 35.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  55%|█████▍    | 7.55G/13.8G [02:55<03:12, 32.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  52%|██████████▊          | 7.10G/13.8G [02:55<04:37, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  52%|██████████▊          | 7.12G/13.8G [02:55<03:25, 32.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  55%|█████▌    | 7.60G/13.8G [02:56<02:40, 38.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  52%|██████████▉          | 7.13G/13.8G [02:56<03:52, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  52%|██████████▉          | 7.13G/13.8G [02:56<03:59, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  88%|███▌| 4.21G/4.79G [02:57<00:21, 26.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  51%|██  | 2.44G/4.80G [02:57<01:41, 23.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  52%|██████████▉          | 7.14G/13.8G [02:57<05:24, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  52%|██  | 2.51G/4.80G [02:57<01:01, 37.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  52%|██████████▉          | 7.16G/13.8G [02:57<04:19, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  88%|███▌| 4.23G/4.79G [02:57<00:20, 27.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  53%|██▏ | 2.56G/4.80G [02:58<00:54, 41.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  52%|██████████▉          | 7.19G/13.8G [02:58<03:00, 36.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  52%|██████████▉          | 7.20G/13.8G [02:58<02:45, 39.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  52%|███████████          | 7.22G/13.8G [02:59<03:28, 31.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  56%|█████▌    | 7.67G/13.8G [02:59<03:16, 30.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  54%|██▏ | 2.57G/4.80G [02:59<01:07, 32.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  56%|█████▌    | 7.74G/13.8G [02:59<02:15, 44.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  53%|███████████          | 7.25G/13.8G [02:59<02:16, 47.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  53%|███████████          | 7.27G/13.8G [02:59<01:54, 56.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  53%|███████████          | 7.28G/13.8G [03:00<02:49, 38.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  55%|██▏ | 2.63G/4.80G [03:00<00:57, 37.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  57%|█████▋    | 7.81G/13.8G [03:00<02:02, 48.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  53%|███████████▏         | 7.29G/13.8G [03:00<02:44, 39.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  57%|█████▋    | 7.88G/13.8G [03:00<01:35, 61.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  53%|███████████▏         | 7.30G/13.8G [03:01<05:17, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  90%|███▌| 4.30G/4.79G [03:01<00:23, 21.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  53%|███████████▏         | 7.31G/13.8G [03:01<04:12, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  53%|███████████▏         | 7.32G/13.8G [03:02<04:28, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  90%|███▌| 4.34G/4.79G [03:02<00:18, 25.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  57%|█████▋    | 7.89G/13.8G [03:02<02:27, 39.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  54%|███████████▎         | 7.37G/13.8G [03:02<01:51, 57.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  54%|███████████▎         | 7.39G/13.8G [03:02<01:37, 65.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  92%|███▋| 4.40G/4.79G [03:02<00:10, 37.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  54%|███████████▎         | 7.42G/13.8G [03:03<01:22, 76.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  55%|██▏ | 2.64G/4.80G [03:03<01:40, 21.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  54%|███████████▎         | 7.44G/13.8G [03:03<01:10, 89.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  54%|███████████▍         | 7.45G/13.8G [03:03<01:05, 96.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  56%|██▏ | 2.67G/4.80G [03:03<01:26, 24.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  57%|██▎ | 2.74G/4.80G [03:04<00:48, 42.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  54%|███████████▍         | 7.47G/13.8G [03:04<02:09, 48.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  54%|███████████▍         | 7.48G/13.8G [03:05<03:43, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  58%|██▎ | 2.76G/4.80G [03:05<01:03, 31.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  55%|███████████▌         | 7.56G/13.8G [03:05<01:35, 64.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  58%|██▎ | 2.78G/4.80G [03:05<00:55, 36.6MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  93%|███▋| 4.45G/4.79G [03:05<00:12, 27.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  58%|█████▊    | 7.96G/13.8G [03:06<03:39, 26.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  55%|███████████▌         | 7.58G/13.8G [03:06<02:22, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  94%|███▊| 4.51G/4.79G [03:06<00:07, 35.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  58%|█████▊    | 7.97G/13.8G [03:06<03:34, 27.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  55%|███████████▌         | 7.59G/13.8G [03:06<02:13, 46.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  56%|███████████▋         | 7.66G/13.8G [03:07<01:33, 64.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  96%|███▊| 4.58G/4.79G [03:07<00:04, 43.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  56%|███████████▋         | 7.68G/13.8G [03:07<01:27, 69.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  56%|███████████▋         | 7.69G/13.8G [03:07<01:21, 74.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  56%|███████████▊         | 7.71G/13.8G [03:08<01:23, 72.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  57%|███████████▉         | 7.78G/13.8G [03:08<01:02, 94.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  57%|████████████▍         | 7.80G/13.8G [03:08<00:58, 101MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  58%|██▎ | 2.80G/4.80G [03:09<01:49, 18.2MB/s]\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  97%|███▊| 4.63G/4.79G [03:09<00:03, 40.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  59%|██▎ | 2.82G/4.80G [03:09<01:31, 21.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  57%|███████████▉         | 7.82G/13.8G [03:09<01:18, 75.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  60%|██▍ | 2.86G/4.80G [03:09<01:05, 29.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  57%|███████████▉         | 7.84G/13.8G [03:09<01:47, 55.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  98%|███▉| 4.70G/4.79G [03:10<00:02, 40.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  57%|███████████▉         | 7.84G/13.8G [03:10<02:49, 34.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  57%|████████████         | 7.86G/13.8G [03:10<02:19, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors:  99%|███▉| 4.72G/4.79G [03:11<00:01, 42.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  57%|████████████         | 7.87G/13.8G [03:11<02:15, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  57%|████████████         | 7.89G/13.8G [03:11<01:46, 55.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00000-of-00002.safetensors: 100%|███▉| 4.79G/4.79G [03:12<00:00, 47.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  57%|████████████         | 7.90G/13.8G [03:12<03:19, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  60%|██▍ | 2.88G/4.80G [03:12<01:53, 16.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  58%|████████████         | 7.92G/13.8G [03:12<02:38, 36.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  58%|█████▊    | 8.04G/13.8G [03:13<05:51, 16.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00000-of-00002.safetensors: 100%|████| 4.79G/4.79G [03:13<00:00, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/model-00000-of-00002.safetensors\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  58%|████████████▏        | 7.96G/13.8G [03:13<02:33, 37.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  61%|██▍ | 2.91G/4.80G [03:14<01:44, 18.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  62%|██▍ | 2.97G/4.80G [03:14<00:56, 32.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  58%|████████████▏        | 7.97G/13.8G [03:14<03:30, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  58%|████████████▏        | 7.99G/13.8G [03:14<02:29, 38.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  59%|█████▉    | 8.11G/13.8G [03:15<04:34, 20.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  58%|████████████▏        | 8.00G/13.8G [03:15<03:15, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  62%|██▍ | 2.98G/4.80G [03:15<01:08, 26.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  64%|██▌ | 3.05G/4.80G [03:15<00:35, 49.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  58%|████████████▏        | 8.02G/13.8G [03:15<02:35, 36.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  58%|████████████▎        | 8.03G/13.8G [03:15<02:02, 46.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  59%|████████████▎        | 8.07G/13.8G [03:15<01:09, 81.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  65%|██▌ | 3.12G/4.80G [03:16<00:31, 54.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  59%|█████▉    | 8.17G/13.8G [03:16<03:36, 25.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  59%|████████████▎        | 8.09G/13.8G [03:16<02:05, 45.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  59%|████████████▎        | 8.10G/13.8G [03:17<02:03, 45.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  59%|████████████▍        | 8.11G/13.8G [03:17<02:07, 44.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  60%|█████▉    | 8.20G/13.8G [03:17<03:21, 27.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  59%|████████████▍        | 8.12G/13.8G [03:17<02:02, 46.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  59%|████████████▍        | 8.13G/13.8G [03:18<03:05, 30.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  66%|██▋ | 3.18G/4.80G [03:18<00:32, 50.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  60%|██████    | 8.27G/13.8G [03:18<02:51, 32.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  59%|████████████▍        | 8.15G/13.8G [03:18<03:30, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  61%|██████    | 8.33G/13.8G [03:19<02:12, 41.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  59%|████████████▍        | 8.16G/13.8G [03:19<04:17, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  59%|████████████▍        | 8.17G/13.8G [03:19<03:42, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  68%|██▋ | 3.25G/4.80G [03:20<00:39, 38.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  60%|████████████▌        | 8.19G/13.8G [03:20<03:38, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  60%|████████████▌        | 8.20G/13.8G [03:20<02:40, 34.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  68%|██▋ | 3.26G/4.80G [03:20<00:37, 40.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  60%|████████████▌        | 8.21G/13.8G [03:20<02:35, 35.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  60%|████████████▋        | 8.29G/13.8G [03:21<01:17, 70.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  60%|████████████▋        | 8.30G/13.8G [03:21<01:27, 62.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  69%|██▊ | 3.33G/4.80G [03:22<00:32, 45.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  60%|████████████▋        | 8.31G/13.8G [03:22<01:42, 52.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  61%|██████    | 8.35G/13.8G [03:22<03:37, 24.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  61%|████████████▋        | 8.32G/13.8G [03:22<01:58, 45.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  61%|████████████▋        | 8.34G/13.8G [03:22<01:31, 59.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  61%|████████████▊        | 8.41G/13.8G [03:23<01:07, 79.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  61%|█████████████▌        | 8.46G/13.8G [03:23<00:47, 112MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  70%|██▊ | 3.34G/4.80G [03:23<00:47, 30.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  61%|██████    | 8.35G/13.8G [03:23<04:31, 19.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  62%|█████████████▌        | 8.51G/13.8G [03:23<00:33, 157MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  62%|█████████████▋        | 8.55G/13.8G [03:23<00:32, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  62%|█████████████▋        | 8.57G/13.8G [03:24<00:30, 169MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  61%|██████    | 8.37G/13.8G [03:24<04:45, 18.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  63%|█████████████▊        | 8.60G/13.8G [03:24<00:40, 126MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  70%|██▊ | 3.35G/4.80G [03:24<00:55, 26.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  63%|█████████████▊        | 8.64G/13.8G [03:24<00:40, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  61%|██████▏   | 8.43G/13.8G [03:25<02:50, 31.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  70%|██▊ | 3.36G/4.80G [03:25<01:07, 21.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  61%|██████▏   | 8.44G/13.8G [03:25<02:47, 31.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  71%|██▊ | 3.43G/4.80G [03:26<00:36, 37.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  62%|██████▏   | 8.51G/13.8G [03:26<01:59, 43.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  72%|██▊ | 3.44G/4.80G [03:26<00:36, 37.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  72%|██▊ | 3.44G/4.80G [03:26<00:35, 37.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73%|██▉ | 3.49G/4.80G [03:27<00:23, 56.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  62%|██████▏   | 8.51G/13.8G [03:27<02:26, 35.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  62%|██████▏   | 8.52G/13.8G [03:27<02:26, 35.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73%|██▉ | 3.50G/4.80G [03:27<00:23, 56.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73%|██▉ | 3.51G/4.80G [03:27<00:31, 40.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  62%|██████▏   | 8.58G/13.8G [03:27<01:27, 59.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  63%|██████▎   | 8.60G/13.8G [03:28<01:24, 61.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  75%|██▉ | 3.58G/4.80G [03:28<00:18, 66.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  76%|███ | 3.65G/4.80G [03:28<00:13, 84.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  63%|██████▎   | 8.62G/13.8G [03:29<02:16, 37.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  63%|██████▎   | 8.69G/13.8G [03:29<01:22, 61.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  77%|███ | 3.72G/4.80G [03:29<00:13, 81.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  78%|███ | 3.73G/4.80G [03:30<00:18, 58.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  79%|███▏| 3.80G/4.80G [03:31<00:11, 85.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  80%|███▏| 3.82G/4.80G [03:31<00:10, 94.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  63%|█████████████▏       | 8.66G/13.8G [03:31<06:13, 13.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  64%|██████▎   | 8.76G/13.8G [03:31<01:44, 48.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  81%|███▏| 3.89G/4.80G [03:32<00:13, 66.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  63%|█████████████▎       | 8.72G/13.8G [03:32<03:51, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  83%|███▎| 3.97G/4.80G [03:32<00:08, 97.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  64%|█████████████▎       | 8.74G/13.8G [03:32<03:39, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  84%|████▏| 4.02G/4.80G [03:32<00:06, 120MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  64%|██████▎   | 8.77G/13.8G [03:33<02:34, 32.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  64%|█████████████▎       | 8.75G/13.8G [03:33<03:24, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  85%|████▏| 4.06G/4.80G [03:33<00:06, 107MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  64%|██████▍   | 8.84G/13.8G [03:33<01:54, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  65%|██████▍   | 8.90G/13.8G [03:34<01:17, 62.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  64%|█████████████▍       | 8.76G/13.8G [03:34<04:08, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  64%|█████████████▍       | 8.77G/13.8G [03:34<03:27, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  64%|█████████████▍       | 8.80G/13.8G [03:34<02:07, 38.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  64%|█████████████▍       | 8.83G/13.8G [03:34<01:45, 46.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  85%|███▍| 4.09G/4.80G [03:34<00:12, 57.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  64%|█████████████▍       | 8.84G/13.8G [03:35<02:00, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  86%|███▍| 4.11G/4.80G [03:35<00:11, 58.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  64%|█████████████▌       | 8.85G/13.8G [03:36<02:56, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  65%|██████▌   | 8.96G/13.8G [03:36<01:48, 44.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  64%|█████████████▌       | 8.86G/13.8G [03:36<02:40, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  87%|███▍| 4.17G/4.80G [03:37<00:16, 37.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  66%|██████▌   | 9.03G/13.8G [03:37<01:46, 44.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  66%|██████▌   | 9.09G/13.8G [03:38<01:20, 57.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  64%|█████████████▌       | 8.87G/13.8G [03:38<05:49, 14.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  67%|██████▋   | 9.16G/13.8G [03:38<01:10, 65.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  65%|█████████████▌       | 8.88G/13.8G [03:38<05:30, 14.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  67%|██████▋   | 9.23G/13.8G [03:39<00:52, 85.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  65%|█████████████▌       | 8.89G/13.8G [03:39<05:16, 15.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  88%|███▌| 4.24G/4.80G [03:39<00:14, 38.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  65%|█████████████▌       | 8.89G/13.8G [03:39<05:32, 14.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  65%|█████████████▌       | 8.90G/13.8G [03:40<04:39, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  68%|██████▊   | 9.31G/13.8G [03:40<00:49, 89.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  65%|█████████████▌       | 8.91G/13.8G [03:40<03:36, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  90%|███▌| 4.31G/4.80G [03:40<00:09, 49.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  65%|█████████████▋       | 8.93G/13.8G [03:40<02:02, 39.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  65%|█████████████▋       | 8.95G/13.8G [03:40<01:27, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  65%|█████████████▋       | 8.97G/13.8G [03:40<01:24, 56.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  91%|███▋| 4.35G/4.80G [03:41<00:08, 50.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  65%|█████████████▋       | 8.97G/13.8G [03:41<01:46, 44.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  92%|███▋| 4.41G/4.80G [03:42<00:07, 52.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  65%|█████████████▋       | 8.99G/13.8G [03:41<03:11, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  92%|███▋| 4.42G/4.80G [03:42<00:06, 54.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  65%|█████████████▋       | 9.00G/13.8G [03:42<02:42, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  94%|███▋| 4.49G/4.80G [03:42<00:04, 62.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  68%|██████▊   | 9.38G/13.8G [03:43<01:37, 45.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  65%|█████████████▋       | 9.00G/13.8G [03:43<05:18, 14.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  68%|██████▊   | 9.39G/13.8G [03:43<01:36, 45.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  94%|███▊| 4.50G/4.80G [03:43<00:06, 46.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  66%|█████████████▊       | 9.01G/13.8G [03:44<06:32, 12.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  69%|██████▊   | 9.46G/13.8G [03:44<01:15, 57.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  69%|██████▉   | 9.53G/13.8G [03:44<00:53, 79.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  66%|█████████████▊       | 9.01G/13.8G [03:44<06:18, 12.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  94%|███▊| 4.52G/4.80G [03:44<00:07, 37.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  66%|█████████████▊       | 9.02G/13.8G [03:44<05:08, 15.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  66%|█████████████▊       | 9.03G/13.8G [03:45<04:31, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  95%|███▊| 4.56G/4.80G [03:45<00:04, 47.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  66%|█████████████▊       | 9.03G/13.8G [03:45<04:43, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  95%|███▊| 4.58G/4.80G [03:45<00:04, 49.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  66%|█████████████▊       | 9.04G/13.8G [03:45<03:37, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  97%|███▊| 4.65G/4.80G [03:45<00:01, 89.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  70%|██████▉   | 9.60G/13.8G [03:46<01:15, 55.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  97%|███▉| 4.68G/4.80G [03:47<00:02, 52.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  66%|█████████████▊       | 9.05G/13.8G [03:47<07:06, 11.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  99%|███▉| 4.74G/4.80G [03:47<00:00, 69.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  66%|█████████████▊       | 9.06G/13.8G [03:47<06:16, 12.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  66%|█████████████▊       | 9.06G/13.8G [03:47<06:13, 12.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors: 100%|███▉| 4.79G/4.80G [03:48<00:00, 76.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  66%|█████████████▊       | 9.07G/13.8G [03:48<03:36, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors: 100%|████| 4.80G/4.80G [03:48<00:00, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/model-00001-of-00002.safetensors\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  66%|█████████████▉       | 9.10G/13.8G [03:48<01:47, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  70%|██████▉   | 9.62G/13.8G [03:48<01:59, 34.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  66%|█████████████▉       | 9.12G/13.8G [03:48<02:04, 37.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  66%|█████████████▉       | 9.14G/13.8G [03:48<01:28, 52.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  70%|███████   | 9.69G/13.8G [03:49<01:38, 41.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  67%|█████████████▉       | 9.15G/13.8G [03:49<02:57, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  71%|███████▏  | 9.82G/13.8G [03:50<00:54, 72.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  72%|███████▏  | 9.89G/13.8G [03:50<00:43, 89.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  67%|█████████████▉       | 9.15G/13.8G [03:50<03:48, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  67%|██████████████       | 9.17G/13.8G [03:50<02:46, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  67%|██████████████       | 9.20G/13.8G [03:51<01:37, 46.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  72%|███████▏  | 9.96G/13.8G [03:51<00:47, 79.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  67%|██████████████       | 9.21G/13.8G [03:51<02:19, 32.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  73%|████████   | 10.0G/13.8G [03:51<00:35, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  67%|██████████████       | 9.22G/13.8G [03:51<01:59, 37.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  73%|███████▎  | 10.1G/13.8G [03:52<00:37, 98.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  67%|██████████████       | 9.23G/13.8G [03:52<02:41, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  67%|██████████████       | 9.24G/13.8G [03:52<02:28, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  68%|██████████████▏      | 9.32G/13.8G [03:53<00:47, 93.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  74%|███████▍  | 10.1G/13.8G [03:53<00:37, 97.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  68%|██████████████▎      | 9.34G/13.8G [03:53<00:45, 97.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  68%|██████████████▎      | 9.36G/13.8G [03:53<00:44, 98.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  68%|██████████████▎      | 9.38G/13.8G [03:54<01:11, 61.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  74%|███████▍  | 10.2G/13.8G [03:54<00:47, 74.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  68%|██████████████▎      | 9.39G/13.8G [03:54<01:32, 47.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  68%|██████████████▎      | 9.41G/13.8G [03:54<01:13, 59.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  75%|████████▏  | 10.3G/13.8G [03:54<00:33, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  69%|██████████████▍      | 9.43G/13.8G [03:54<00:58, 73.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  75%|███████▌  | 10.4G/13.8G [03:55<00:36, 93.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  69%|██████████████▍      | 9.45G/13.8G [03:55<01:38, 43.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  69%|██████████████▍      | 9.49G/13.8G [03:55<00:57, 74.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  69%|██████████████▌      | 9.51G/13.8G [03:56<00:47, 88.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  76%|███████▌  | 10.4G/13.8G [03:56<00:36, 91.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  76%|████████▍  | 10.5G/13.8G [03:56<00:29, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  77%|███████▋  | 10.6G/13.8G [03:58<00:35, 90.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  69%|██████████████▌      | 9.53G/13.8G [03:58<02:23, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  77%|███████▋  | 10.6G/13.8G [03:58<00:33, 93.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  69%|██████████████▌      | 9.55G/13.8G [03:58<01:52, 37.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  78%|███████▊  | 10.7G/13.8G [03:58<00:33, 92.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  70%|██████████████▌      | 9.57G/13.8G [03:58<02:11, 31.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  70%|██████████████▋      | 9.58G/13.8G [03:59<01:54, 36.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  78%|████████▌  | 10.7G/13.8G [03:59<00:24, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  70%|██████████████▋      | 9.60G/13.8G [03:59<01:30, 45.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  70%|██████████████▋      | 9.62G/13.8G [03:59<01:17, 53.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  78%|███████▊  | 10.8G/13.8G [03:59<00:31, 96.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  70%|██████████████▋      | 9.63G/13.8G [03:59<01:18, 52.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  70%|██████████████▋      | 9.65G/13.8G [03:59<01:00, 67.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  70%|██████████████▊      | 9.67G/13.8G [04:00<01:06, 61.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  79%|███████▊  | 10.8G/13.8G [04:00<00:31, 91.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  79%|███████▉  | 10.9G/13.8G [04:01<00:32, 87.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  70%|██████████████▊      | 9.68G/13.8G [04:01<02:25, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  70%|██████████████▊      | 9.69G/13.8G [04:01<02:08, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  71%|██████████████▊      | 9.71G/13.8G [04:01<01:29, 45.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  71%|██████████████▊      | 9.73G/13.8G [04:01<01:18, 51.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  71%|██████████████▉      | 9.74G/13.8G [04:02<01:12, 55.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  80%|███████▉  | 11.0G/13.8G [04:02<00:35, 78.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  71%|██████████████▉      | 9.75G/13.8G [04:02<01:36, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  71%|██████████████▉      | 9.78G/13.8G [04:02<00:54, 72.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  71%|██████████████▉      | 9.80G/13.8G [04:02<00:49, 79.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  80%|████████  | 11.1G/13.8G [04:03<00:33, 81.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  71%|██████████████▉      | 9.81G/13.8G [04:03<01:15, 52.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  71%|███████████████      | 9.82G/13.8G [04:03<01:07, 57.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  80%|████████  | 11.1G/13.8G [04:03<00:34, 77.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  72%|███████████████      | 9.84G/13.8G [04:03<01:00, 64.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  72%|███████████████      | 9.86G/13.8G [04:03<00:53, 72.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  72%|███████████████      | 9.88G/13.8G [04:04<00:40, 94.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  72%|███████████████▊      | 9.91G/13.8G [04:04<00:33, 115MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  81%|████████  | 11.1G/13.8G [04:05<00:47, 55.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  81%|████████▏ | 11.2G/13.8G [04:06<00:43, 58.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  72%|███████████████▏     | 9.93G/13.8G [04:06<02:39, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  82%|████████▏ | 11.3G/13.8G [04:06<00:28, 86.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  82%|█████████  | 11.3G/13.8G [04:06<00:20, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  72%|███████████████▏     | 9.94G/13.8G [04:06<02:17, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  72%|███████████████▏     | 9.95G/13.8G [04:06<01:48, 35.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  73%|███████████████▏     | 9.98G/13.8G [04:07<01:37, 38.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  83%|█████████▏ | 11.4G/13.8G [04:07<00:21, 108MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  73%|███████████████▎     | 9.99G/13.8G [04:07<01:49, 34.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  73%|███████████████▎     | 10.0G/13.8G [04:07<01:21, 46.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  83%|████████▎ | 11.5G/13.8G [04:08<00:28, 79.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  73%|███████████████▎     | 10.0G/13.8G [04:09<01:45, 35.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  84%|████████▍ | 11.6G/13.8G [04:09<00:28, 77.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  84%|████████▍ | 11.6G/13.8G [04:10<00:28, 75.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  73%|███████████████▎     | 10.0G/13.8G [04:10<03:27, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  85%|█████████▍ | 11.7G/13.8G [04:11<00:17, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  73%|███████████████▎     | 10.1G/13.8G [04:11<03:22, 18.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  73%|███████████████▍     | 10.1G/13.8G [04:11<02:21, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  73%|███████████████▍     | 10.1G/13.8G [04:11<02:14, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  86%|█████████▍ | 11.8G/13.8G [04:11<00:17, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  73%|███████████████▍     | 10.1G/13.8G [04:11<01:56, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  86%|█████████▍ | 11.9G/13.8G [04:12<00:18, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  74%|███████████████▍     | 10.1G/13.8G [04:12<01:27, 41.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  87%|█████████▌ | 11.9G/13.8G [04:12<00:15, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  74%|███████████████▍     | 10.1G/13.8G [04:12<01:50, 32.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  74%|███████████████▍     | 10.1G/13.8G [04:12<01:38, 36.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  74%|███████████████▌     | 10.2G/13.8G [04:12<01:01, 58.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  74%|███████████████▌     | 10.2G/13.8G [04:13<00:54, 66.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  87%|████████▋ | 11.9G/13.8G [04:13<00:19, 93.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  74%|███████████████▌     | 10.2G/13.8G [04:13<00:56, 63.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  74%|███████████████▌     | 10.2G/13.8G [04:13<00:53, 66.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  87%|█████████▌ | 12.0G/13.8G [04:13<00:16, 104MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  74%|███████████████▌     | 10.2G/13.8G [04:13<01:20, 44.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  87%|█████████▌ | 12.0G/13.8G [04:14<00:16, 103MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  74%|███████████████▌     | 10.2G/13.8G [04:14<01:11, 49.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  74%|███████████████▋     | 10.2G/13.8G [04:14<00:39, 88.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  75%|███████████████▋     | 10.3G/13.8G [04:14<00:35, 98.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  88%|████████▊ | 12.0G/13.8G [04:14<00:20, 83.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  88%|█████████▋ | 12.1G/13.8G [04:14<00:15, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  75%|███████████████▋     | 10.3G/13.8G [04:15<01:34, 36.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  89%|████████▊ | 12.2G/13.8G [04:16<00:20, 78.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  75%|███████████████▋     | 10.3G/13.8G [04:16<02:10, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  75%|███████████████▋     | 10.3G/13.8G [04:16<01:47, 32.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  75%|███████████████▋     | 10.3G/13.8G [04:16<01:25, 40.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  89%|████████▊ | 12.2G/13.8G [04:16<00:25, 60.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  90%|█████████▊ | 12.3G/13.8G [04:17<00:13, 102MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  75%|███████████████▊     | 10.3G/13.8G [04:17<02:46, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  75%|███████████████▊     | 10.3G/13.8G [04:17<02:10, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  75%|███████████████▊     | 10.4G/13.8G [04:18<01:04, 52.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  76%|███████████████▊     | 10.4G/13.8G [04:18<01:07, 49.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  76%|███████████████▉     | 10.4G/13.8G [04:18<00:58, 57.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  76%|████████████████▊     | 10.5G/13.8G [04:18<00:24, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  90%|█████████ | 12.4G/13.8G [04:18<00:16, 82.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  76%|████████████████▊     | 10.5G/13.8G [04:19<00:28, 115MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  77%|████████████████     | 10.5G/13.8G [04:19<00:34, 94.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  77%|████████████████▉     | 10.6G/13.8G [04:19<00:19, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  77%|████████████████▉     | 10.6G/13.8G [04:19<00:21, 146MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  77%|█████████████████     | 10.6G/13.8G [04:20<00:26, 119MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  78%|████████████████▎    | 10.7G/13.8G [04:20<00:34, 90.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  78%|████████████████▎    | 10.7G/13.8G [04:20<00:42, 72.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  78%|████████████████▎    | 10.7G/13.8G [04:21<00:41, 74.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  91%|█████████ | 12.5G/13.8G [04:21<00:26, 48.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  91%|█████████ | 12.5G/13.8G [04:21<00:21, 57.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  92%|█████████▏| 12.6G/13.8G [04:22<00:16, 72.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  92%|█████████▏| 12.7G/13.8G [04:23<00:16, 65.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  78%|████████████████▎    | 10.7G/13.8G [04:23<02:29, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  92%|█████████▏| 12.7G/13.8G [04:23<00:11, 87.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  78%|████████████████▎    | 10.7G/13.8G [04:24<02:30, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  93%|█████████▎| 12.8G/13.8G [04:24<00:11, 85.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  78%|████████████████▍    | 10.7G/13.8G [04:24<02:15, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  94%|██████████▎| 12.9G/13.8G [04:24<00:06, 133MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  79%|████████████████▍    | 10.8G/13.8G [04:25<00:58, 50.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  79%|████████████████▌    | 10.8G/13.8G [04:26<01:23, 35.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  94%|█████████▍| 13.0G/13.8G [04:26<00:10, 77.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  95%|█████████▍| 13.0G/13.8G [04:26<00:07, 96.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  79%|████████████████▌    | 10.8G/13.8G [04:26<01:22, 35.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  95%|█████████▌| 13.1G/13.8G [04:27<00:06, 95.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  79%|████████████████▌    | 10.9G/13.8G [04:27<01:40, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  79%|████████████████▌    | 10.9G/13.8G [04:27<01:26, 33.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  96%|██████████▌| 13.2G/13.8G [04:27<00:04, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  79%|████████████████▌    | 10.9G/13.8G [04:27<01:19, 36.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  79%|████████████████▋    | 10.9G/13.8G [04:28<01:12, 39.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  96%|██████████▌| 13.2G/13.8G [04:28<00:04, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  79%|████████████████▋    | 10.9G/13.8G [04:28<01:16, 37.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  97%|██████████▋| 13.3G/13.8G [04:29<00:04, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  79%|████████████████▋    | 10.9G/13.8G [04:29<01:58, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  80%|████████████████▋    | 10.9G/13.8G [04:29<01:04, 43.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  80%|████████████████▋    | 11.0G/13.8G [04:29<00:39, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  80%|████████████████▊    | 11.0G/13.8G [04:29<00:38, 72.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  80%|████████████████▊    | 11.0G/13.8G [04:30<00:44, 61.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  97%|█████████▋| 13.4G/13.8G [04:30<00:04, 90.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  80%|████████████████▊    | 11.0G/13.8G [04:30<00:35, 76.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  98%|█████████▊| 13.4G/13.8G [04:30<00:03, 88.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  80%|████████████████▉    | 11.1G/13.8G [04:30<00:42, 62.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  98%|█████████▊| 13.5G/13.8G [04:31<00:03, 90.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  81%|████████████████▉    | 11.1G/13.8G [04:31<00:35, 75.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  81%|████████████████▉    | 11.1G/13.8G [04:31<00:32, 82.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  98%|█████████▊| 13.5G/13.8G [04:32<00:02, 82.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  81%|████████████████▉    | 11.1G/13.8G [04:32<01:01, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  81%|█████████████████    | 11.1G/13.8G [04:32<00:47, 55.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  81%|█████████████████    | 11.2G/13.8G [04:32<00:38, 66.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  81%|█████████████████▉    | 11.2G/13.8G [04:32<00:23, 109MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  82%|█████████████████▉    | 11.2G/13.8G [04:32<00:23, 106MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  82%|█████████████████▉    | 11.2G/13.8G [04:32<00:18, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  82%|██████████████████    | 11.3G/13.8G [04:33<00:23, 106MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  82%|██████████████████    | 11.3G/13.8G [04:33<00:22, 112MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors:  99%|█████████▉| 13.6G/13.8G [04:34<00:02, 55.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  82%|█████████████████▎   | 11.3G/13.8G [04:34<00:49, 49.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors: 100%|█████████▉| 13.7G/13.8G [04:34<00:00, 67.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  82%|█████████████████▎   | 11.3G/13.8G [04:34<01:05, 37.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  83%|█████████████████▎   | 11.3G/13.8G [04:35<00:41, 58.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/model.safetensors: 100%|██████████| 13.8G/13.8G [04:35<00:00, 71.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "original/model.safetensors: 100%|██████████| 13.8G/13.8G [04:35<00:00, 49.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/original/model.safetensors\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  83%|█████████████████▍   | 11.4G/13.8G [04:36<00:32, 72.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  83%|█████████████████▍   | 11.5G/13.8G [04:36<00:25, 90.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  84%|██████████████████▍   | 11.5G/13.8G [04:36<00:17, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  84%|██████████████████▍   | 11.5G/13.8G [04:36<00:16, 134MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  84%|██████████████████▍   | 11.5G/13.8G [04:36<00:15, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  84%|██████████████████▌   | 11.6G/13.8G [04:36<00:14, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  84%|██████████████████▌   | 11.6G/13.8G [04:37<00:16, 131MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  85%|██████████████████▌   | 11.6G/13.8G [04:37<00:13, 158MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  85%|██████████████████▋   | 11.7G/13.8G [04:37<00:19, 108MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  85%|██████████████████▋   | 11.7G/13.8G [04:37<00:19, 109MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  85%|██████████████████▋   | 11.7G/13.8G [04:37<00:18, 110MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  85%|██████████████████▊   | 11.7G/13.8G [04:38<00:15, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  85%|██████████████████▊   | 11.7G/13.8G [04:38<00:13, 145MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  86%|██████████████████▊   | 11.8G/13.8G [04:38<00:11, 172MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  86%|██████████████████▊   | 11.8G/13.8G [04:38<00:10, 186MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  86%|██████████████████▉   | 11.8G/13.8G [04:38<00:11, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  86%|██████████████████▉   | 11.8G/13.8G [04:38<00:11, 170MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  86%|██████████████████▉   | 11.9G/13.8G [04:38<00:12, 151MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  87%|███████████████████   | 11.9G/13.8G [04:39<00:07, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  87%|███████████████████   | 11.9G/13.8G [04:39<00:07, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  87%|███████████████████▏  | 12.0G/13.8G [04:39<00:09, 188MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  87%|███████████████████▏  | 12.0G/13.8G [04:39<00:12, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  88%|███████████████████▎  | 12.0G/13.8G [04:39<00:09, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  88%|███████████████████▎  | 12.1G/13.8G [04:39<00:09, 172MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  88%|███████████████████▎  | 12.1G/13.8G [04:40<00:12, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  89%|███████████████████▍  | 12.2G/13.8G [04:40<00:09, 168MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  89%|███████████████████▌  | 12.2G/13.8G [04:40<00:09, 162MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  89%|███████████████████▌  | 12.2G/13.8G [04:41<00:09, 165MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  89%|███████████████████▌  | 12.3G/13.8G [04:41<00:08, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  89%|███████████████████▋  | 12.3G/13.8G [04:41<00:08, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  90%|███████████████████▋  | 12.3G/13.8G [04:41<00:08, 169MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  90%|███████████████████▋  | 12.3G/13.8G [04:41<00:09, 155MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  90%|███████████████████▊  | 12.4G/13.8G [04:41<00:08, 165MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  90%|███████████████████▊  | 12.4G/13.8G [04:41<00:08, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  90%|███████████████████▊  | 12.4G/13.8G [04:42<00:08, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  90%|███████████████████▉  | 12.4G/13.8G [04:42<00:08, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  91%|███████████████████▉  | 12.5G/13.8G [04:42<00:08, 149MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  91%|███████████████████▉  | 12.5G/13.8G [04:42<00:08, 151MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  91%|████████████████████  | 12.5G/13.8G [04:42<00:05, 241MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  92%|████████████████████▏ | 12.6G/13.8G [04:42<00:04, 279MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  92%|████████████████████▏ | 12.6G/13.8G [04:43<00:06, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  92%|████████████████████▏ | 12.6G/13.8G [04:43<00:07, 154MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  92%|████████████████████▎ | 12.7G/13.8G [04:43<00:08, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  92%|████████████████████▎ | 12.7G/13.8G [04:44<00:09, 111MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  92%|████████████████████▎ | 12.7G/13.8G [04:44<00:08, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  93%|███████████████████▍ | 12.7G/13.8G [04:44<00:12, 80.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  93%|███████████████████▍ | 12.8G/13.8G [04:44<00:11, 84.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  93%|███████████████████▌ | 12.8G/13.8G [04:45<00:12, 75.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  93%|███████████████████▌ | 12.8G/13.8G [04:45<00:11, 81.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  94%|████████████████████▋ | 12.9G/13.8G [04:46<00:06, 123MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  94%|████████████████████▋ | 12.9G/13.8G [04:46<00:07, 116MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  94%|████████████████████▋ | 12.9G/13.8G [04:46<00:06, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  94%|████████████████████▊ | 13.0G/13.8G [04:46<00:05, 150MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  95%|████████████████████▊ | 13.0G/13.8G [04:46<00:05, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  95%|████████████████████▊ | 13.0G/13.8G [04:47<00:04, 150MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  95%|████████████████████▉ | 13.1G/13.8G [04:47<00:05, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  95%|████████████████████▉ | 13.1G/13.8G [04:47<00:05, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  95%|████████████████████▉ | 13.1G/13.8G [04:47<00:05, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  95%|████████████████████ | 13.1G/13.8G [04:47<00:06, 98.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  96%|█████████████████████ | 13.1G/13.8G [04:47<00:04, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  96%|█████████████████████ | 13.2G/13.8G [04:48<00:04, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  96%|█████████████████████ | 13.2G/13.8G [04:48<00:03, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  96%|█████████████████████▏| 13.2G/13.8G [04:48<00:03, 152MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  96%|█████████████████████▏| 13.2G/13.8G [04:48<00:03, 152MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  96%|█████████████████████▏| 13.2G/13.8G [04:48<00:03, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  96%|████████████████████▎| 13.3G/13.8G [04:49<00:05, 91.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  97%|████████████████████▎| 13.3G/13.8G [04:49<00:05, 91.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  97%|█████████████████████▎| 13.3G/13.8G [04:49<00:04, 102MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  97%|█████████████████████▎| 13.3G/13.8G [04:49<00:03, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  97%|█████████████████████▎| 13.3G/13.8G [04:49<00:02, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  97%|█████████████████████▎| 13.4G/13.8G [04:49<00:02, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  97%|█████████████████████▍| 13.4G/13.8G [04:49<00:02, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  97%|█████████████████████▍| 13.4G/13.8G [04:49<00:02, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  98%|█████████████████████▍| 13.4G/13.8G [04:50<00:03, 109MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  98%|█████████████████████▌| 13.4G/13.8G [04:50<00:02, 131MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  98%|█████████████████████▌| 13.5G/13.8G [04:50<00:01, 176MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  98%|█████████████████████▌| 13.5G/13.8G [04:50<00:01, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  98%|█████████████████████▋| 13.5G/13.8G [04:50<00:01, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  98%|█████████████████████▋| 13.5G/13.8G [04:50<00:01, 177MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  99%|█████████████████████▋| 13.6G/13.8G [04:50<00:00, 222MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  99%|█████████████████████▊| 13.6G/13.8G [04:51<00:00, 157MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  99%|█████████████████████▊| 13.6G/13.8G [04:51<00:00, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  99%|█████████████████████▊| 13.6G/13.8G [04:51<00:00, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin:  99%|█████████████████████▊| 13.7G/13.8G [04:51<00:00, 119MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin: 100%|████████████████████▉| 13.7G/13.8G [04:52<00:00, 95.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin: 100%|█████████████████████▉| 13.7G/13.8G [04:52<00:00, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metal/model.bin: 100%|█████████████████████| 13.8G/13.8G [04:52<00:00, 47.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to models/openai-gpt-oss-20b/metal/model.bin\n",
      "Fetching 18 files: 100%|████████████████████████| 18/18 [04:52<00:00, 16.28s/it]\n",
      "/home/ec2-user/SageMaker/llm_deploy_gcr/sagemaker/sagemaker_vllm/models/openai-gpt-oss-20b\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli download --resume-download {MODEL_ID} --local-dir {local_model_path} --max-workers 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upload to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/chat_template.jinja.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/chat_template.jinja.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/README.md.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/README.md.metadata\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/USAGE_POLICY.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/USAGE_POLICY.metadata\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/chat_template.jinja.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/chat_template.jinja.metadata\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/.gitignore s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/.gitignore\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/config.json.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/config.json.metadata\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/config.json.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/config.json.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/LICENSE.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/LICENSE.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/README.md.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/README.md.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/USAGE_POLICY.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/USAGE_POLICY.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/metal/model.bin.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/metal/model.bin.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/generation_config.json.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/generation_config.json.metadata\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/.gitattributes.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/.gitattributes.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/original/dtypes.json.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/original/dtypes.json.metadata\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/.gitattributes.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/.gitattributes.metadata\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/metal/model.bin.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/metal/model.bin.metadata\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/model-00001-of-00002.safetensors.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/model-00001-of-00002.safetensors.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/model-00001-of-00002.safetensors.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/model-00001-of-00002.safetensors.metadata\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/model-00000-of-00002.safetensors.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/model-00000-of-00002.safetensors.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/model.safetensors.index.json.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/model.safetensors.index.json.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/model-00002-of-00002.safetensors.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/model-00002-of-00002.safetensors.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/LICENSE.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/LICENSE.metadata\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/original/model.safetensors.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/original/model.safetensors.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/original/model.safetensors.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/original/model.safetensors.metadata\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/tokenizer.json.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/tokenizer.json.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/special_tokens_map.json.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/special_tokens_map.json.metadata\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/tokenizer_config.json.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/tokenizer_config.json.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/special_tokens_map.json.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/special_tokens_map.json.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/model-00000-of-00002.safetensors.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/model-00000-of-00002.safetensors.metadata\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/model-00002-of-00002.safetensors.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/model-00002-of-00002.safetensors.metadata\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/generation_config.json.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/generation_config.json.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/original/dtypes.json.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/original/dtypes.json.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/original/config.json.lock s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/original/config.json.lock\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/model.safetensors.index.json.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/model.safetensors.index.json.metadata\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/tokenizer.json.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/tokenizer.json.metadata\n",
      "cp models/openai-gpt-oss-20b/.gitattributes s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.gitattributes\n",
      "cp models/openai-gpt-oss-20b/USAGE_POLICY s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/USAGE_POLICY\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/original/config.json.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/original/config.json.metadata\n",
      "cp models/openai-gpt-oss-20b/generation_config.json s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/generation_config.json\n",
      "cp models/openai-gpt-oss-20b/chat_template.jinja s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/chat_template.jinja\n",
      "cp models/openai-gpt-oss-20b/README.md s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/README.md\n",
      "cp models/openai-gpt-oss-20b/original/config.json s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/original/config.json\n",
      "cp models/openai-gpt-oss-20b/.cache/huggingface/download/tokenizer_config.json.metadata s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/.cache/huggingface/download/tokenizer_config.json.metadata\n",
      "cp models/openai-gpt-oss-20b/tokenizer_config.json s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/tokenizer_config.json\n",
      "cp models/openai-gpt-oss-20b/config.json s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/config.json\n",
      "cp models/openai-gpt-oss-20b/special_tokens_map.json s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/special_tokens_map.json\n",
      "cp models/openai-gpt-oss-20b/model.safetensors.index.json s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/model.safetensors.index.json\n",
      "cp models/openai-gpt-oss-20b/original/dtypes.json s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/original/dtypes.json\n",
      "cp models/openai-gpt-oss-20b/LICENSE s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/LICENSE\n",
      "cp models/openai-gpt-oss-20b/tokenizer.json s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/tokenizer.json\n",
      "cp models/openai-gpt-oss-20b/model-00002-of-00002.safetensors s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/model-00002-of-00002.safetensors\n",
      "cp models/openai-gpt-oss-20b/model-00000-of-00002.safetensors s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/model-00000-of-00002.safetensors\n",
      "cp models/openai-gpt-oss-20b/model-00001-of-00002.safetensors s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/model-00001-of-00002.safetensors\n",
      "cp models/openai-gpt-oss-20b/original/model.safetensors s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/original/model.safetensors\n",
      "cp models/openai-gpt-oss-20b/metal/model.bin s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b/metal/model.bin\n",
      "s3_model_path: s3://sagemaker-us-west-2-340636688520/pretrained-models/openai/gpt-oss-20b\n"
     ]
    }
   ],
   "source": [
    "!s5cmd sync --concurrency 32 {local_model_path}/ {s3_model_path}/\n",
    "print(\"s3_model_path:\", s3_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 Prepare vllm start scripts\n",
    "\n",
    "Then you need to a write the vllm starting scripts for endpoint, the container will automatically use the `start.sh` as the entrypont.\n",
    "\n",
    "Please carefully modify the startup script file as needed, such as the model running parameter information. All parameters can be referenced at [https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html](https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html)\n",
    "\n",
    "Here is a simple script that pulling a model from S3 and starting a vllm server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_code_path: openai-gpt-oss-20b-250927-1352\n"
     ]
    }
   ],
   "source": [
    "endpoint_model_name = sagemaker.utils.name_from_base(model_name, short=True)\n",
    "local_code_path = endpoint_model_name\n",
    "s3_code_path = f\"s3://{default_bucket}/endpoint_code/vllm_byoc/{endpoint_model_name}.tar.gz\"\n",
    "\n",
    "%mkdir -p {local_code_path}\n",
    "\n",
    "print(\"local_code_path:\", local_code_path)\n",
    "\n",
    "with open(f\"{local_code_path}/start.sh\", \"w\") as f:\n",
    "    f.write(f\"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "# download model to local\n",
    "s5cmd sync --concurrency 64 \\\n",
    "    {s3_model_path}/* /temp/model_weight\n",
    "\n",
    "\n",
    "# the start script need to be adjust as you needed\n",
    "# port needs to be $SAGEMAKER_BIND_TO_PORT\n",
    "export VLLM_ATTENTION_BACKEND=TRITON_ATTN_VLLM_V1\n",
    "python3 -m vllm.entrypoints.openai.api_server \\\\\n",
    "    --port $SAGEMAKER_BIND_TO_PORT \\\\\n",
    "    --trust-remote-code \\\\\n",
    "    --gpu-memory-utilization 0.95 \\\\\n",
    "    --tool-call-parser openai \\\\\n",
    "    --enable-auto-tool-choice \\\\\n",
    "    --reasoning-parser openai_gptoss \\\\\n",
    "    --max-model-len 32768 \\\\\n",
    "    --served-model-name {MODEL_ID} \\\\\n",
    "    --model /temp/model_weight\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai-gpt-oss-20b-250927-1352/\n",
      "openai-gpt-oss-20b-250927-1352/start.sh\n",
      "upload: ./openai-gpt-oss-20b-250927-1352.tar.gz to s3://sagemaker-us-west-2-340636688520/endpoint_code/vllm_byoc/openai-gpt-oss-20b-250927-1352.tar.gz\n",
      "s3_code_path: s3://sagemaker-us-west-2-340636688520/endpoint_code/vllm_byoc/openai-gpt-oss-20b-250927-1352.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!rm -f {local_code_path}.tar.gz\n",
    "!tar czvf {local_code_path}.tar.gz {local_code_path}/\n",
    "!aws s3 cp {local_code_path}.tar.gz {s3_code_path}\n",
    "print(\"s3_code_path:\", s3_code_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 Deploy endpoint on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelArn': 'arn:aws:sagemaker:us-west-2:340636688520:model/openai-gpt-oss-20b-250927-1352', 'ResponseMetadata': {'RequestId': '47d48afc-f8f7-4c4d-a081-22a1904e670d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '47d48afc-f8f7-4c4d-a081-22a1904e670d', 'strict-transport-security': 'max-age=47304000; includeSubDomains', 'x-frame-options': 'DENY', 'content-security-policy': \"frame-ancestors 'none'\", 'cache-control': 'no-cache, no-store, must-revalidate', 'x-content-type-options': 'nosniff', 'content-type': 'application/x-amz-json-1.1', 'content-length': '92', 'date': 'Sat, 27 Sep 2025 13:52:40 GMT'}, 'RetryAttempts': 0}}\n",
      "endpoint_model_name: openai-gpt-oss-20b-250927-1352\n"
     ]
    }
   ],
   "source": [
    "# Step 0. create model\n",
    "\n",
    "# endpoint_model_name already defined in above step\n",
    "\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName=endpoint_model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": CONTAINER,\n",
    "        \"ModelDataUrl\": s3_code_path\n",
    "    },\n",
    "    \n",
    ")\n",
    "print(create_model_response)\n",
    "print(\"endpoint_model_name:\", endpoint_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EndpointConfigArn': 'arn:aws:sagemaker:us-west-2:340636688520:endpoint-config/openai-gpt-oss-20b-250927-1352', 'ResponseMetadata': {'RequestId': '00f8604c-c078-45ac-947e-f3c8fa395d95', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '00f8604c-c078-45ac-947e-f3c8fa395d95', 'strict-transport-security': 'max-age=47304000; includeSubDomains', 'x-frame-options': 'DENY', 'content-security-policy': \"frame-ancestors 'none'\", 'cache-control': 'no-cache, no-store, must-revalidate', 'x-content-type-options': 'nosniff', 'content-type': 'application/x-amz-json-1.1', 'content-length': '111', 'date': 'Sat, 27 Sep 2025 13:52:43 GMT'}, 'RetryAttempts': 0}}\n",
      "endpoint_config_name: openai-gpt-oss-20b-250927-1352\n"
     ]
    }
   ],
   "source": [
    "# Step 1. create endpoint config\n",
    "\n",
    "endpoint_config_name = sagemaker.utils.name_from_base(model_name, short=True)\n",
    "\n",
    "endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": endpoint_model_name,\n",
    "            \"InstanceType\": INSTANCE_TYPE,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 1000,\n",
    "            # \"EnableSSMAccess\": True,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(endpoint_config_response)\n",
    "print(\"endpoint_config_name:\", endpoint_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EndpointArn': 'arn:aws:sagemaker:us-west-2:340636688520:endpoint/openai-gpt-oss-20b-250927-1352', 'ResponseMetadata': {'RequestId': '90d7af80-8960-4162-a7d6-c086c4e18c97', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '90d7af80-8960-4162-a7d6-c086c4e18c97', 'strict-transport-security': 'max-age=47304000; includeSubDomains', 'x-frame-options': 'DENY', 'content-security-policy': \"frame-ancestors 'none'\", 'cache-control': 'no-cache, no-store, must-revalidate', 'x-content-type-options': 'nosniff', 'content-type': 'application/x-amz-json-1.1', 'content-length': '98', 'date': 'Sat, 27 Sep 2025 13:52:47 GMT'}, 'RetryAttempts': 0}}\n",
      "endpoint_config_name: openai-gpt-oss-20b-250927-1352\n",
      "20250927-13:52:47 status: Creating\n",
      "20250927-13:53:47 status: Creating\n",
      "20250927-13:54:47 status: Creating\n",
      "20250927-13:55:47 status: Creating\n",
      "20250927-13:56:47 status: Creating\n",
      "20250927-13:57:47 status: Creating\n",
      "20250927-13:58:47 status: Creating\n",
      "20250927-13:59:48 status: Creating\n",
      "20250927-14:00:48 status: Creating\n",
      "20250927-14:01:48 status: Creating\n",
      "20250927-14:02:48 status: Creating\n",
      "20250927-14:03:48 status: Creating\n",
      "20250927-14:04:48 status: Creating\n",
      "Endpoint created: openai-gpt-oss-20b-250927-1352\n"
     ]
    }
   ],
   "source": [
    "# Step 2. create endpoint\n",
    "\n",
    "endpoint_name = sagemaker.utils.name_from_base(model_name, short=True)\n",
    "\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(create_endpoint_response)\n",
    "print(\"endpoint_config_name:\", endpoint_name)\n",
    "while 1:\n",
    "    status = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)[\"EndpointStatus\"]\n",
    "    if status != \"Creating\":\n",
    "        break\n",
    "    print(datetime.now().strftime('%Y%m%d-%H:%M:%S') + \" status: \" + status)\n",
    "    time.sleep(60)\n",
    "print(\"Endpoint created:\", endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test\n",
    "\n",
    "You can invoke your model with SageMaker runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Hi, who are you!\"\n",
    "}]\n",
    "\n",
    "max_tokens = 4096"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Message api non-stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! I’m ChatGPT—an AI language model created by OpenAI. I’m here to help answer questions, chat, or assist with a wide range of topics. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "sagemaker_runtime = boto3.client('runtime.sagemaker')\n",
    "\n",
    "payload = {\n",
    "    \"model\": MODEL_ID,\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": max_tokens,\n",
    "    \"stream\": False\n",
    "}\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2 Message api stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning:\n",
      "So user wants a seven-character regulated poem (七言律诗) to introduce Shanghai. Chinese poem with 8 lines, each line 7 characters. Two couplets with parallelism, each pair of lines must correspond. Should depict Shanghai: modern metropolis, historic, coffee, Bund etc. He wants to \"介绍上海\" i.e., introduce Shanghai. Should be classical style but with focus on Shanghai. Keep regulated tone: right, left parts, punctuation.\n",
      "\n",
      "We need to think about Chinese classic regulated poem forms: 8 lines, each of 7 characters. It has structure: 2 quatrains (4 lines each). The 3rd and 4th lines (inner couplet) must be parallel, same number of characters, same grammatical function, echo each other. The 7th line must have the same number of characters as the 3rd and 4th lines, but a different head (but sometimes matches too). Also, the 8th line is the closing statements, essentially the summary.\n",
      "\n",
      "We need to incorporate environment: The Bund, neon lights, stats. It's okay to have modern terms like \"灯火\" etc. It's a regulated poem, but we can use contemporary references. Might not be 100% strict but should follow the spirit.\n",
      "\n",
      "Possible lines: \"梧桐轻摇月映城，烟波江上旧别离...\" But that's more traditional. We want modern aspects: \"浦江映日波光蓝\" \"沪城云集万象\" \"红桥呈夜\" etc.\n",
      "\n",
      "Let's design:\n",
      "\n",
      "Line 1: \"浦江春色映金辉\" 7 chars? Count: \"浦\"(1) \"江\"(2) \"春\"(3) \"色\"(4) \"映\"(5) \"金\"(6) \"辉\"(7). Good.\n",
      "\n",
      "Line 2: \"新天桥影绵星雾\" Count: \"新\"(1) \"天\"(2) \"桥\"(3) \"影\"(4) \"绵\"(5) \"星\"(6) \"雾\"(7)\n",
      "\n",
      "But we need 7 char each. Good.\n",
      "\n",
      "Line 3: \"灯火辉煌千层雾\" Count: \"灯\"(1) \"火\"(2) \"辉\"(3) \"煌\"(4) \"千\"(5) \"层\"(6) \"雾\"(7). Good.\n",
      "\n",
      "But line 4 must parallel line 3: same grammatical, same structure. For example: \"潮声回荡一湾歌\" Count: \"潮\"(1) \"声\"(2) \"回\"(3) \"荡\"(4) \"一\"(5) \"湾\"(6) \"歌\"(7). Good.\n",
      "\n",
      "Line 5: \"古港留影望星辰\" Count: \"古\"(1) \"港\"(2) \"留\"(3) \"影\"(4) \"望\"(5) \"星\"(6) \"辰\"(7)\n",
      "\n",
      "Line 6: \"今朝春暖迎客啸\" Count: \"今\"(1) \"朝\"(2) \"春\"(3) \"暖\"(4) \"迎\"(5) \"客\"(6) \"啸\"(7).\n",
      "\n",
      "But again we need to match meter & parallelism lines but this is fine.\n",
      "\n",
      "But perhaps better to create 8 lines all 7 chars, with 2 couplets and inner parallelism. We could incorporate references like \"外滩\" or \"陆家嘴\". Use \"外滩\" 2 characters. But we can use them.\n",
      "\n",
      "Let's try:\n",
      "\n",
      "Line 1: \"外滩光影映潮霞\" Count: \"外\"(1) \"滩\"(2) \"光\"(3) \"影\"(4) \"映\"(5) \"潮\"(6) \"霞\"(7)\n",
      "\n",
      "Line 2: \"陆家空中云聚金\" Count: \"陆\"(1) \"家\"(2) \"空\"(3) \"中\"(4) \"云\"(5) \"聚\"(6) \"金\"(7) Good.\n",
      "\n",
      "Line 3: \"灯火珠帘照街翠\" Count: \"灯\"(1) \"火\"(2) \"珠\"(3) \"帘\"(4) \"照\"(5) \"街\"(6) \"翠\"(7)\n",
      "\n",
      "Line 4: \"潮声鹭影舞波青\" Count: \"潮\"(1) \"声\"(2) \"鹭\"(3) \"影\"(4) \"舞\"(5) \"波\"(6) \"青\"(7)\n",
      "\n",
      "But line 3 & 4: parse grammar: line 3 is \"灯火珠帘照街翠\" maybe \"灯火珠帘照街翠\" meaning \"little column of lights\". Not perfect maybe. But something like \"灯火迎潮缭曲\" Variation? We'll refine.\n",
      "\n",
      "Alternatively choose: line 3: \"灯火流光映街头\" Count: \"灯\"(1) \"火\"(2) \"流\"(3) \"光\"(4) \"映\"(5) \"街\"(6) \"头\"(7). line 4: \"潮声回荡伴雾雨\" Count: \"潮\"(1) \"声\"(2) \"回\"(3) \"荡\"(4) \"伴\"(5) \"雾\"(6) \"雨\"(7). They are parallel? \"灯火流光映街头\" vs \"潮声回荡伴雾雨\" same structure? Both start with a noun, verb, verb, complement, object? Hard but fine.\n",
      "\n",
      "But we need the poem to be a \"七言律诗\", which requires parallelism: the 3rd and 4th lines must be parallel in structure, and the 5th and 6th lines also parallel. So we need line 5 & 6 to be again parallel.\n",
      "\n",
      "Line 5: \"古渡留芳迎雨客\" Count: \"古\"(1) \"渡\"(2) \"留\"(3) \"芳\"(4) \"迎\"(5) \"雨\"(6) \"客\"(7)\n",
      "\n",
      "Line 6: \"新街装饰送春风\" Count: \"新\"(1) \"街\"(2) \"装\"(3) \"饰\"(4) \"送\"(5) \"春\"(6) \"风\"(7)\n",
      "\n",
      "But 5 and 6 parallel? Both are \"名词+名词+动词+动词+the something\"? Not perfect.\n",
      "\n",
      "Let's refine with actual parallel grammar: Example of parallel lines: \"世外桃源\" vs \"问君何处\" etc.\n",
      "\n",
      "Better approach: Write a poem with meter fine:\n",
      "\n",
      "Line 1: \"外滩潮起映金霞\" Count: \"外\"(1) \"滩\"(2) \"潮\"(3) \"起\"(4) \"映\"(5) \"金\"(6) \"霞\"(7)\n",
      "\n",
      "Line 2: \"陆家嘴影聚聚弧\" Count: \"陆\"(1) \"家\"(2) \"嘴\"(3) \"影\"(4) \"聚\"(5) \"聚\"(6) \"弧\"(7) maybe redundant.\n",
      "\n",
      "We need 7 char exactly. Maybe drop \"聚\" duplicates, so \"陆家嘴影拥弧\". Count: \"陆\"(1) \"家\"(2) \"嘴\"(3) \"影\"(4) \"拥\"(5) \"弧\"(6) (only 6). Need 7, add \"深\". \"陆家嘴影拥深弧\". Count: \"陆\"(1) \"家\"(2) \"嘴\"(3) \"影\"(4) \"拥\"(5) \"深\"(6) \"弧\"(7). Good.\n",
      "\n",
      "Line 3: \"灯火漫天照江潮\" Count: \"灯\"(1) \"火\"(2) \"漫\"(3) \"天\"(4) \"照\"(5) \"江\"(6) \"潮\"(7)\n",
      "\n",
      "Line 4: \"潮声回荡舞潮雾\" Count: \"潮\"(1) \"声\"(2) \"回\"(3) \"荡\"(4) \"舞\"(5) \"潮\"(6) \"雾\"(7)\n",
      "\n",
      "But we need line 3 and 4 parallel: both start with \"灯火...\" vs \"潮声...\", good structure. They each have 5+2+1? \"灯火漫天照江潮\" (noun+verb+verb+verb...?). \"潮声回荡舞潮雾\" (noun+verb+verb+verb+...?). Good.\n",
      "\n",
      "Line 5: \"古港留映纪洪波\" Count: \"古\"(1) \"港\"(2) \"留\"(3) \"映\"(4) \"纪\"(5) \"洪\"(6) \"波\"(7) Might not be good.\n",
      "\n",
      "Line 6: \"新街绽放迎往今\" Count: \"新\"(1) \"街\"(2) \"绽\"(3) \"放\"(4) \"迎\"(5) \"往\"(6) \"今\"(7) but 6 & 7 are big. Eh.\n",
      "\n",
      "Alternatively we could adopt a more traditional style, referencing \"烟雨江南\" etc but avoid.\n",
      "\n",
      "Let's step back: write an 8-line 7-character regulated poem:\n",
      "\n",
      "We'll keep line 1: \"外滩潮光映日红\". Count: \"外\"(1) \"滩\"(2) \"潮\"(3) \"光\"(4) \"映\"(5) \"日\"(6) \"红\"(7)\n",
      "\n",
      "Line 2: \"陆家嘴影聚星辉\". Count: \"陆\"(1) \"家\"(2) \"嘴\"(3) \"影\"(4) \"聚\"(5) \"星\"(6) \"辉\"(7)\n",
      "\n",
      "Line 3: \"灯火繁华映夜空\". Count: \"灯\"(1) \"火\"(2) \"繁\"(3) \"华\"(4) \"映\"(5) \"夜\"(6) \"空\"(7)\n",
      "\n",
      "Line 4: \"潮声浪起鸣寰宇\". Count: \"潮\"(1) \"声\"(2) \"浪\"(3) \"起\"(4) \"鸣\"(5) \"寰\"(6) \"宇\"(7). They are parallel?\n",
      "\n",
      "Line 5: \"古渡烟波抒昔梦\". Count: \"古\"(1) \"渡\"(2) \"烟\"(3) \"波\"(4) \"抒\"(5) \"昔\"(6) \"梦\"(7)\n",
      "\n",
      "Line 6: \"新城绿影映朝晖\". Count: \"新\"(1) \"城\"(2) \"绿\"(3) \"影\"(4) \"映\"(5) \"朝\"(6) \"晖\"(7)\n",
      "\n",
      "Line 7: \"海湾远客辞东风\". Count: \"海\"(1) \"湾\"(2) \"远\"(3) \"客\"(4) \"辞\"(5) \"东\"(6) \"风\"(7)\n",
      "\n",
      "Line 8: \"沪墨丹青笔买风\". Count: \"沪\"(1) \"墨\"(2) \"丹\"(3) \"青\"(4) \"笔\"(5) \"买\"(6) \"风\"(7) but \"买风\" fine? Might not make sense.\n",
      "\n",
      "We need better.\n",
      "\n",
      "Alternate: line 7 like \"潮涌香波访故人\". Count: \"潮\"(1) \"涌\"(2) \"香\"(3) \"波\"(4) \"访\"(5) \"故\"(6) \"人\"(7). Great.\n",
      "\n",
      "Line 8: \"一路繁华君映我\". Count: \"一\"(1) \"路\"(2) \"繁\"(3) \"华\"(4) \"君\"(5) \"映\"(6) \"我\"(7). That sums the poem.\n",
      "\n",
      "Let's box the final poem.\n",
      "\n",
      "Actually we need to use a subjective voice? Write like a description: \"白天外滩灯光 红夜...\".\n",
      "\n",
      "I think we should produce a better polished poem:\n",
      "\n",
      "First line: \"外滩潮光映金霞\" (7)\n",
      "Second: \"陆家嘴影聚星辉\" (7)\n",
      "Third: \"灯火繁华映夜空\" (7)\n",
      "Fourth: \"潮声回荡入云雾\" (7)\n",
      "Fifth: \"古渡烟波抒客心\" (7)\n",
      "Sixth: \"新城绿影映朝晖\" (7)\n",
      "Seventh: \"海湾远客系海潮\" (7)\n",
      "Eighth: \"沪墨丹青勾画图\" (7)\n",
      "\n",
      "Now check line 3 and 4: \"灯火繁华映夜空\" and \"潮声回荡入云雾\": both pattern: [N1 V3 V3 V3] but not exactly.\n",
      "\n",
      "Better to build with standard parallelism pattern: 3rd & 4th lines: object subject complement? Example: \"灯火照江潮\" vs \"潮声响渔舟\"? But after writing we may accept.\n",
      "\n",
      "Let's produce final poem with some punctuation and mention glimpses of Shanghai.\n",
      "\n",
      "Final approach:\n",
      "\n",
      "Line 1: 外滩潮光映金霞 (7)\n",
      "Line 2: 陆家嘴影聚星辉 (7)\n",
      "Line 3: 灯火流光映街头 (7)\n",
      "Line 4: 潮声回荡曲澜波 (7)\n",
      "Line 5: 古渡烟波抒旧梦 (7)\n",
      "Line 6: 新街绿影映朝晖 (7)\n",
      "Line 7: 海湾远客随潮起 (7)\n",
      "Line 8: 沪墨丹青勾画图 (7)\n",
      "\n",
      "Check each 7 char. Count:\n",
      "\n",
      "Line 1: 外(1)滩(2)潮(3)光(4)映(5)金(6)霞(7)\n",
      "Line 2: 陆(1)家(2)嘴(3)影(4)聚(5)星(6)辉(7)\n",
      "Line 3: 灯(1)火(2)流(3)光(4)映(5)街(6)头(7)\n",
      "Line 4: 潮(1)声(2)回(3)荡(4)曲(5)澜(6)波(7)\n",
      "Line 5: 古(1)渡(2)烟(3)波(4)抒(5)旧(6)梦(7)\n",
      "Line 6: 新(1)街(2)绿(3)影(4)映(5)朝(6)晖(7)\n",
      "Line 7: 海(1)湾(2)远(3)客(4)随(5)潮(6)起(7)\n",
      "Line 8: 沪(1)墨(2)丹(3)青(4)勾(5)画(6)图(7)\n",
      "\n",
      "Parallel lines? 3 vs4: \"灯火流光映街头\" vs \"潮声回荡曲澜波\". Not perfect but at least symmetrical.\n",
      "\n",
      "5 vs 6: \"古渡烟波抒旧梦\" vs \"新街绿影映朝晖\". They not parallel in structure but fine.\n",
      "\n",
      "However a regulated poem requires strict parallelism. But the user might want a simple introduction poem rather than rigorous. Might not need top-level strictness. Provide an opening, object, moods.\n",
      "\n",
      "We can mention \"烟雨\". Another version:\n",
      "\n",
      "外滩潮光映金霞\n",
      "陆家嘴影聚星辉\n",
      "灯火摇晓映江影\n",
      "潮声回响映雨雾\n",
      "古渡烟波抒旧忆\n",
      "新街绿影映朝晖\n",
      "海湾远客随潮起\n",
      "沪墨丹青勾画图\n",
      "\n",
      "Check each line:\n",
      "\n",
      "Line1: 7 char: 外1滩2潮3光4映5金6霞7\n",
      "Line2: 陆1家2嘴3影4聚5星6辉7\n",
      "Line3: 灯1火2摇3晓4映5江6影7\n",
      "Line4: 潮1声2回3响4映5雨6雾7\n",
      "Line5: 古1渡2烟3波4抒5旧6忆7\n",
      "Line6: 新1街2绿3影4映5朝6晖7\n",
      "Line7: 海1湾2远3客4随5潮6起7\n",
      "Line8: 沪1墨2丹3青4勾5画6图7\n",
      "\n",
      "Parallel: 3rd vs 4th lines \"灯火摇晓映江影\" vs \"潮声回响映雨雾\": both have pattern noun+verb+adverb+verb+Verb+?? Actually pattern: noun (灯火) - verb (摇) - adverb (晓) - verb (映) - noun (江影). Similarly: 潮声-回响-映-雨雾. They share structure but not identical. 5th vs 6th similar? \"古渡烟波抒旧忆\" vs \"新街绿影映朝晖\". Similar pattern: noun (古渡) - noun (烟波) - verb (抒) - noun (旧忆). Next: noun (新街) - noun (绿影) - verb (映) - noun (朝晖). But 4th component difference: 抒 vs 映. That might be fine as some variation.\n",
      "\n",
      "Ok deliver final poem. Provide description.**七言律诗——《绍沪寄怀》**\n",
      "\n",
      "外滩潮光映金霞，  \n",
      "陆家嘴影聚星辉。  \n",
      "灯火摇晓映江影，  \n",
      "潮声回响映雨雾。  \n",
      "古渡烟波抒旧忆，  \n",
      "新街绿影映朝晖。  \n",
      "海湾远客随潮起，  \n",
      "沪墨丹青勾画图。  \n",
      "\n",
      "*此诗以“外滩”与“陆家嘴”为地标，描绘了上海的夜色与现代摩天楼的灯火；随后以潮声、雨雾与古渡烟波表现江南气息；再以新街与绿影映照城市的青春与朝气；终以海湾与穿梭客旅、墨笔勾勒上海的国际风貌。*\n"
     ]
    }
   ],
   "source": [
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"帮我写一首七言律诗介绍上海\"\n",
    "}]\n",
    "\n",
    "max_tokens = 4096\n",
    "\n",
    "\n",
    "payload = {\n",
    "    \"model\": MODEL_ID,\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": max_tokens,\n",
    "    \"extra_body\": {\"reasoning_effort\": \"medium\"},\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "print(f\"Reasoning:\")\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "   \n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.span()[1]\n",
    "\n",
    "            #若不希望打印reasoning过程，可以去掉下两行\n",
    "            if \"reasoning_content\" in data[\"choices\"][0][\"delta\"]:\n",
    "                print(f\"{data['choices'][0]['delta']['reasoning_content']}\", end=\"\")\n",
    "            #打印最后的正式输出内容    \n",
    "            print(data[\"choices\"][0][\"delta\"][\"content\"], end=\"\")\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.2.1 Message api stream mode--function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== Tool Calls Detected ===\n",
      "Tool Call 1:\n",
      "  Function: get_weather\n",
      "  Arguments: {\"location\":\"Beijing, China\",\"unit\":\"celsius\"}\n",
      "  Result: Getting the weather for Beijing, China in celsius...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# 定义工具函数\n",
    "def get_weather(location: str, unit: str = \"celsius\"):\n",
    "    \"\"\"获取指定位置的天气信息\"\"\"\n",
    "    return f\"Getting the weather for {location} in {unit}...\"\n",
    "\n",
    "def calculate_sum(a: float, b: float):\n",
    "    \"\"\"计算两个数字的和\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# 定义可用的工具\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\", \n",
    "                        \"description\": \"City and state, e.g., 'San Francisco, CA'\"\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\", \n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"Temperature unit\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculate_sum\",\n",
    "            \"description\": \"Calculate the sum of two numbers\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
    "                    \"b\": {\"type\": \"number\", \"description\": \"Second number\"}\n",
    "                },\n",
    "                \"required\": [\"a\", \"b\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# 定义消息内容\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"请帮我查询北京的天气，然后计算25和17的和\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 修改后的 payload\n",
    "payload = {\n",
    "    \"model\": MODEL_ID,\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": max_tokens,\n",
    "    \"stream\": True,\n",
    "    \"tools\": tools,                    # 添加工具定义\n",
    "    \"tool_choice\": \"auto\"              # 让模型自动决定是否调用工具\n",
    "}\n",
    "\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "# 修改响应处理逻辑\n",
    "buffer = \"\"\n",
    "collected_tool_calls = []\n",
    "current_content = \"\"\n",
    "\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    \n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.span()[1]\n",
    "            \n",
    "            choice = data[\"choices\"][0]\n",
    "            delta = choice.get(\"delta\", {})\n",
    "            \n",
    "            # 处理常规内容\n",
    "            if \"content\" in delta and delta[\"content\"]:\n",
    "                current_content += delta[\"content\"]\n",
    "                print(delta[\"content\"], end=\"\")\n",
    "            \n",
    "            # 处理工具调用\n",
    "            if \"tool_calls\" in delta and delta[\"tool_calls\"]:\n",
    "                for tool_call_delta in delta[\"tool_calls\"]:\n",
    "                    index = tool_call_delta.get(\"index\", 0)\n",
    "                    \n",
    "                    # 确保 collected_tool_calls 有足够的空间\n",
    "                    while len(collected_tool_calls) <= index:\n",
    "                        collected_tool_calls.append({\n",
    "                            \"id\": \"\",\n",
    "                            \"type\": \"function\",\n",
    "                            \"function\": {\"name\": \"\", \"arguments\": \"\"}\n",
    "                        })\n",
    "                    \n",
    "                    # 更新工具调用信息\n",
    "                    if \"id\" in tool_call_delta:\n",
    "                        collected_tool_calls[index][\"id\"] = tool_call_delta[\"id\"]\n",
    "                    \n",
    "                    if \"function\" in tool_call_delta:\n",
    "                        func_delta = tool_call_delta[\"function\"]\n",
    "                        if \"name\" in func_delta:\n",
    "                            collected_tool_calls[index][\"function\"][\"name\"] += func_delta[\"name\"]\n",
    "                        if \"arguments\" in func_delta:\n",
    "                            collected_tool_calls[index][\"function\"][\"arguments\"] += func_delta[\"arguments\"]\n",
    "            \n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    \n",
    "    buffer = buffer[last_idx:]\n",
    "\n",
    "print()\n",
    "\n",
    "# 处理工具调用结果\n",
    "if collected_tool_calls:\n",
    "    print(\"\\n=== Tool Calls Detected ===\")\n",
    "    tool_functions = {\n",
    "        \"get_weather\": get_weather,\n",
    "        \"calculate_sum\": calculate_sum\n",
    "    }\n",
    "    \n",
    "    for i, tool_call in enumerate(collected_tool_calls):\n",
    "        if tool_call[\"function\"][\"name\"]:  # 确保工具名称不为空\n",
    "            func_name = tool_call[\"function\"][\"name\"]\n",
    "            func_args = tool_call[\"function\"][\"arguments\"]\n",
    "            \n",
    "            print(f\"Tool Call {i+1}:\")\n",
    "            print(f\"  Function: {func_name}\")\n",
    "            print(f\"  Arguments: {func_args}\")\n",
    "            \n",
    "            try:\n",
    "                # 解析参数并调用函数\n",
    "                args = json.loads(func_args) if func_args else {}\n",
    "                if func_name in tool_functions:\n",
    "                    result = tool_functions[func_name](**args)\n",
    "                    print(f\"  Result: {result}\")\n",
    "                else:\n",
    "                    print(f\"  Error: Unknown function {func_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error executing function: {e}\")\n",
    "            print()\n",
    "\n",
    "# 如果有常规内容，显示最终内容\n",
    "if current_content.strip():\n",
    "    print(f\"\\nFinal Content: {current_content.strip()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Completion api non-stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysisUser wants a seven-character regulated poem (七言律诗) introducing Shanghai. Need to follow classical Chinese prosody: 8 lines, each of 7 characters. Theme about Shanghai. Should include imagery of modern skyscrapers, city skyline, river, maybe the Bund, Nanjing Road, etc. Use regulated poem style: alternating rhyme? Traditional schemes BA, AB, etc? In Chinese poetry, 7-character regulated poem has 4 couplets (8 lines). Each line 7 characters. It should follow \"平仄\" patterns; but here we just produce approximate. Also typical rhythm with rhyme in even lines. Provide Chinese text. Provide romanization optional? Probably just Chinese poem.\n",
      "\n",
      "Let's propose:\n",
      "\n",
      "春风吹浦江，  \n",
      "金波映天际。  \n",
      "沪岛灯火阑，  \n",
      "人潮似浪矫。  \n",
      "外滩古今汇，  \n",
      "东方明珠跃虚空。  \n",
      "滩头行船沉，  \n",
      "海路通天覆。\n",
      "\n",
      "Let's check char count: each line 7 characters.\n",
      "\n",
      "Line1: 春风吹浦江 (4? Actually \"春风吹浦江\" has 4 characters? Wait: 春(1)风(2)吹(3)浦(4)江(5). That's 5. Need 7. Let's count again. Might need 7 characters each. We'll craft proper lines.\n",
      "\n",
      "Let's plan:\n",
      "\n",
      "Line1: 春风吹浦江水 (7? 春1 风2 吹3 浦4 江5 水6 ) only 6. Add one char: \"远\" maybe. So: 春风吹浦江远水 (7). Good.\n",
      "\n",
      "Line2: 金波映天际灯 (7? 金1 波2 映3 天4 辺4? Wait: 天 5, 边 6, 灯?? Actually need 7 char. Let's rewrite: \"金波映天际灯\". Count: 金1 波2 映3 天4 边? Wait we didn't use 边. Let's just choose words carefully.\n",
      "\n",
      "Let's start again step by step.\n",
      "\n",
      "Better approach: craft regulated poem with 7 characters per line using classical imagery.\n",
      "\n",
      "Line1: 春风吹浦江岸 (春1 风2 吹3 浦4 江5 岸6). 6 char, need 1 more. Add \"远\" at end: 春风吹浦江岸远 (7). Good.\n",
      "\n",
      "Line2: 金波映天际灯 (金1 波2 映3 天4 边? Actually \"天际\" is two characters: 天3? Wait we need to count precisely.\n",
      "\n",
      "Let's count: 金(1) 波(2) 映(3) 天(4) 边? But we wrote \"天际灯\". Let's break: 天(4) 边? Actually \"天际\" two chars: 天4, 边? No \"际\" is char 5. Then 灯6. That's 6. Need 1 more char maybe \"高\". So line: 金波映天际灯高? Not good. Let's think different.\n",
      "\n",
      "We can write: 金波映岱天灯. Hmm.\n",
      "\n",
      "Maybe better to step back and design first couplet elegantly.\n",
      "\n",
      "Let's start with first couplet about spring breeze and river. Use \"春风吹浦江远岸，金波竟照灯塔光\" etc. Let's attempt.\n",
      "\n",
      "We must have 7 characters each.\n",
      "\n",
      "We need to maintain rhymes to help. Chinese regulated poems have rhyme in even lines, usually using the same rhyme. Let's choose a rhyme like \"兴\". But easier choose rhyme \"光\" for even lines maybe. Typically 1-2-3-4-5-6-7-8 lines; even lines rhyme. So lines 2,4,6,8 rhyme.\n",
      "\n",
      "Let's pick rhyme \"泪\" or \"路\" or \"景\"? Let's choose \"宁\", \"平\". Let's just use \"宁\" rhymes? But we can be flexible.\n",
      "\n",
      "Better to keep simple: left lines 2,4,6,8 all end with same character maybe \"光\" or \"市\". Let's choose \"夜\" maybe. Use \"夜\" at end of lines 2,4,6,8. But 7-character lines, can't all end with same char as we need rhyme. Use \"港\" maybe. Let's pick \"港\" as common rhyme.\n",
      "\n",
      "Let's think: Line2 end \"港\". Line4 end \"港\". Line6 end \"港\". Line8 end \"港\". That's possible.\n",
      "\n",
      "Ok.\n",
      "\n",
      "Create four couplets:\n",
      "\n",
      "Couplet 1 lines1-2:\n",
      "Line1: 春风吹浦江远岸 (春1 风2 吹3 浦4 江5 远6 岸7) ok 7.\n",
      "Line2: 金波映古今灯照港 (金1 波2 映3 古4 今5 灯6 照7 港8) 8 sorry. Need 7 only. Let's adjust: 金波映古灯照港 (金1 波2 映3 古4 灯5 照6 港7). Good. So line2 ends 港, rhymes.\n",
      "\n",
      "Couplet 2 lines3-4:\n",
      "Line3: 外滩灯影随潮吹 (外1 滩2 灯3 影4 随5 潮6 吹7) good.\n",
      "Line4: 人潮如浪舞红灯港 (人1 潮2 如3 浪4 舞5 红6 灯7 港8) 8 char. We need 7. Remove maybe \"红\". Option: 人潮如浪舞灯港 (人1 潮2 如3 浪4 舞5 灯6 港7). Fine.\n",
      "\n",
      "Couplet 3 lines5-6:\n",
      "Line5: 东方明珠高耸缠云 (东1 方2 明3 珠4 高5 耸6 缠7 云8) 8. Need 7. Remove maybe \"东\" or \"缠\". Let's try: 东方明珠高耸云 (东1 方2 明3 珠4 高5 耸6 云7). Good, ends 云, but we want rhyme with 港? If keep rhyme, must end with 岸? Actually we want rhyme in even lines: lines2,4,6,8. So line6 must end with same char as lines2 and4 and8. Lines2 ends 港, line4 ends 港. So line6 should also end 港. Let's adjust.\n",
      "\n",
      "Line5 can be something else maybe \"潮涌江心\" etc. Let's think again.\n",
      "\n",
      "We have 8 lines; we need to produce 7 char each.\n",
      "\n",
      "Maybe design from scratch with a consistent rhyme \"港\".\n",
      "\n",
      "Couplets wise:\n",
      "\n",
      "Line1: 春风吹浪在浦江 (春1 风2 吹3 浪4 在5 浦6 江7) ends 江 not rhyming but that's fine for odd lines not necessarily rhyme.\n",
      "\n",
      "Line2: 金波映古灯光照港 (金1 波2 映3 古4 灯5 光6 照7 港8) 8 char again. We need 7. Maybe \"金波映古灯照港\" (金1 波2 映3 古4 灯5 照6 港7). Good, ends 港.\n",
      "\n",
      "Line3: 外滩霓虹映潮曲 (外1 滩2 霓3 虹4 映5 潮6 曲7). ends 曲.\n",
      "\n",
      "Line4: 夜色星光映灯塔港 (夜1 色2 星3 光4 映5 灯6 塔7 港8). Need 7. Remove maybe \"星\". \"夜色光映灯塔港\" (夜1 色2 光3 映4 灯5 塔6 港7). Good, ends 港 again.\n",
      "\n",
      "Line5: 东方明珠连云际 (东1 方2 明3 珠4 连5 云6 隔7). Ends 隔.\n",
      "\n",
      "Line6: 高楼拔地横连港 (高1 楼2 拔3 地4 横5 连6 港7). ends 港.\n",
      "\n",
      "Line7: 流珠浪响穿街巷 (流1 珠2 浪3 响4 穿5 街6 巷7). ends 巷.\n",
      "\n",
      "Line8: 人潮汹涌映灯市港 (人1 潮2 汹3 涌4 映5 灯6 市7 港8). Need 7. Remove maybe \"灯\". \"人潮汹涌映市港\" (人1 潮2 汹3 涌4 映5 市6 港7). ends 港.\n",
      "\n",
      "Check char counts: we have to verify each line 7.\n",
      "\n",
      "Let's rewrite final 8 lines:\n",
      "\n",
      "1. 春风吹浪在浦江\n",
      "Count: 春1 风2 吹3 浪4 在5 浦6 江7 => 7 okay.\n",
      "\n",
      "2. 金波映古灯照港\n",
      "金1 波2 映3 古4 灯5 照6 港7 => 7 okay.\n",
      "\n",
      "3. 外滩霓虹映潮曲\n",
      "外1 滩2 霓3 虹4 映5 潮6 曲7 => 7 okay.\n",
      "\n",
      "4. 夜色光映灯塔港\n",
      "夜1 色2 光3 映4 灯5 塔6 港7 => 7 okay.\n",
      "\n",
      "5. 东方明珠连云际\n",
      "东1 方2 明3 珠4 连5 云6 隔7 => 7 okay.\n",
      "\n",
      "6. 高楼拔地横连港\n",
      "高1 楼2 拔3 地4 横5 连6 港7 => 7 okay.\n",
      "\n",
      "7. 流珠浪响穿街巷\n",
      "流1 珠2 浪3 响4 穿5 街6 巷7 => 7 okay.\n",
      "\n",
      "8. 人潮汹涌映市港\n",
      "人1 潮2 汹3 涌4 映5 市6 港7 => 7 okay.\n",
      "\n",
      "Nice. It rhymes lines 2,4,6,8 with 港; lines1,3,5,7 not. That's fine.\n",
      "\n",
      "Now we can present this as the answer.\n",
      "\n",
      "But the user asked \"帮我写一首七言律诗介绍上海\" meaning: \"Help me write a seven-character regulated poem introducing Shanghai.\" So deliver the poem. Provide perhaps translation or explanation. But likely only the poem. Might add a small explanation after. But answer in Chinese.\n",
      "\n",
      "Let's produce poem:\n",
      "\n",
      "春风吹浪在浦江  \n",
      "金波映古灯照港  \n",
      "外滩霓虹映潮曲  \n",
      "夜色光映灯塔港  \n",
      "东方明珠连云际  \n",
      "高楼拔地横连港  \n",
      "流珠浪响穿街巷  \n",
      "人潮汹涌映市港\n",
      "\n",
      "We might want to add some more classical elements: mention \"黄浦\" \"外滩\" etc. But okay. Maybe incorporate \"千古\" \"新旧\". But it's fine.\n",
      "\n",
      "Let's produce as final. Also mention that this poem describes Shanghai's coastline, The Bund, skyline, modernity, nightlife, commerce, etc.\n",
      "\n",
      "Answer.assistantfinal**七言律诗：上海序奏**\n",
      "\n",
      "春风吹浪在浦江  \n",
      "金波映古灯照港  \n",
      "外滩霓虹映潮曲  \n",
      "夜色光映灯塔港  \n",
      "东方明珠连云际  \n",
      "高楼拔地横连港  \n",
      "流珠浪响穿街巷  \n",
      "人潮汹涌映市港  \n",
      "\n",
      "*这首七言律诗以春风、浦江、外滩、明珠、高楼等典型景象，既描绘了上海的海滨与繁华，也体现了其现代都市与人潮涌动的活力。*\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path, trust_remote_code=True)\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "\n",
    "payload = {\n",
    "    \"model\": MODEL_ID,\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": max_tokens,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Completion api stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\n",
      "Knowledge cutoff: 2024-06\n",
      "Current date: 2025-09-28\n",
      "\n",
      "Reasoning: medium\n",
      "\n",
      "# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>user<|message|>帮我写一首七言律诗介绍上海<|end|><|start|>assistant\n",
      "======\n",
      "analysisThe user wants a 七言律诗 (seven-character regulated verse) introducing Shanghai. Likely 8 lines, each of 7 characters, following the structural rules: two quatrains (four lines each), with tonal pattern, rhyme, parallelism. Should introduce Shanghai: its history, modernity, Bund, skyline, Huangpu River, etc.\n",
      "\n",
      "We need to ensure 7-character lines, regulated form. It must be in Chinese.\n",
      "\n",
      "We can craft:\n",
      "\n",
      "Line1: (must start with \"海纳\", maybe \"海纳百川\") but 7 chars: \"海纳百川好\" is 8. \"海纳百川\" is 5. Perhaps we can start \"海滨古玩转\", but 7 chars.\n",
      "\n",
      "We need to include rhyme: Usually final rhyme in 8 lines same rhyme. For 七言律诗, the rhyme positions are at 2,4,6,...? In a 8-line poem, rhyme on lines 2,4,6,8. Let's pick a rhyme like -an, -en, -an? Common rhyme.\n",
      "\n",
      "We could use the classic pattern: 1 R, 2 A, 3 R, 4 A, 5 R, 6 A, 7 R, 8 A? Wait: For a regulated verse, the pattern is: For a 8-line poem, the first line is a neutral, second line rhymes. Actually 7-7 lines. Standard: (要点) For a 8-line poem: the pattern of tone: 1: y平 (yin?) Actually Chinese tones: Ping (level) and Tone (rising). The regulated verse had specific tonal pattern: For a 7-7-cha, the pattern for 8 lines:\n",
      "\n",
      "Line 1: ① (y) ② (y) ③ (i) ④ (i) ⑤ (y) ⑥ (y) ⑦ (y)\n",
      "... Hmm. But that might be too complex to fully follow. Possibly we can satisfy basic regulatory criteria: have parallelism (lines 3-4 and 7-8) and rhyme.\n",
      "\n",
      "We might not need to strictly follow the most intricate tonal rules, as likely the user wants a nice poem about Shanghai.\n",
      "\n",
      "We can create a poem:\n",
      "\n",
      "Line1: \"海角天涯照港城\" (海角, 天涯, 兆? Count chars: 海(1) 角(2) 天(3)涯(4)照(5)港(6)城(7) => 7. Good.)\n",
      "\n",
      "Line2: \"繁花似锦映烟波\" Count: 繁(1)花(2)似(3)锦(4)映(5)烟(6)波(7) => 7. Must rhyme with word ending -波? Rhyme indicated? \"波\" is rhymed. The rhyme might be -o? In Chinese, \"波\" is a rhyme tone \"ao\"? Might be okay.\n",
      "\n",
      "Line3: \"衣锦还乡铁骑马\" Count: 衣(1)锦(2)还(3)乡(4)铁(5)骑(6)马(7). Then line4: \"彩旗繁映寒江蓝\". Count: 彩(1)旗(2)繁(3)映(4)寒(5)江(6)蓝(7). But line3 and line4 should be parallel: \"衣锦还乡铁骑马\" vs \"彩旗繁映寒江蓝\"? Not obviously parallel.\n",
      "\n",
      "We need better design.\n",
      "\n",
      "Let's think of the poem structure: We want to reflect Shanghai's history: glistening harbor, Bund, pearl differences between old and new.\n",
      "\n",
      "Perhaps the lines:\n",
      "\n",
      "Line1: “海港如镜照潮生” Wait 7 chars: 海(1)港(2)如(3)镜(4)照(5)潮(6)生(7). Good.\n",
      "\n",
      "Line2: “古桥梦回不夜灯” 古(1)桥(2)梦(3)回(4)不(5)夜(6)灯(7) good. Rhyme? \"灯\" maybe.\n",
      "\n",
      "Line3: “金沙江畔风吹绿” 斤? Check: 金沙(1)江(2)畔(3)风(4)吹(5)绿(6)??? Need 7 char. Maybe \"金沙江畔风吹绿\" that's 8? Let's count: 金(1)沙(2)江(3)畔(4)风(5)吹(6)绿(7). Yes. Good. But line3 must intersperse tones, but fine.\n",
      "\n",
      "Line4: “老街旧巷满潮声” 老(1)街(2)旧(3)巷(4)满(5)潮(6)声(7). Good. Parallel to line3: \"金沙江畔风吹绿\" vs \"老街旧巷满潮声\"? Might need to be similar structure: X Y Z in line3, similar in line4.\n",
      "\n",
      "Alternatively, can choose: line3: “金风送爽沧浪起” (金風送爽沧浪起) Let's count: 金(1)風(2)送(3)爽(4)沧(5)浪(6)起(7) good. line4: “古城路边人声似” Count: 古(1)城(2)路(3)边(4)人(5)声(6)似(7) good. But parallel is not perfect.\n",
      "\n",
      "Alternatively, use classic pattern:\n",
      "\n",
      "Maybe better structure:\n",
      "\n",
      "Line1: “海角天涯照庙妥” no.\n",
      "\n",
      "Better approach: Use known example of regulated verse: \"山重水复疑无路，柳暗花明又一村\" Not appropriate.\n",
      "\n",
      "Let's design:\n",
      "\n",
      "We need 8 lines, each 7 characters. Let's choose a rhyme ending with \"城\" or \"城\" is typical rhyme for Shanghai? Possibly \"城\" - (/eng?) The Chinese rhyme scheme can be 'c' to rhyme. Let's choose \"城\" as rhyme. Lines 2,4,6,8 each end with \"城\". Then it's a rhyme scheme A,B,A,B... Actually 2,4,6,8 rhyme. Let's make them end with \"城\".\n",
      "\n",
      "Line1: \"海角波澜映浦城\" Count: 海(1)角(2)波(3)澜(4)映(5)浦(6)城(7). Rhyme? Ends with \"城\", good.\n",
      "\n",
      "Line2: \"灯火通明换旧城\" Count: 灯(1)火(2)通(3)明(4)换(5)旧(6)城(7).\n",
      "\n",
      "Line3: \"银光霓虹合眼前\" Count: 银(1)光(2)霓(3)虹(4)合(5)眼(6)前(7). Does not rhyme.\n",
      "\n",
      "Line4: \"古运河里声声城\" Count: 古(1)运(2)河(3)里(4)声(5)声(6)城(7). Good.\n",
      "\n",
      "Line5: \"江畔风帆洗旧梦\" Count: 江(1)畔(2)风(3)帆(4)洗(5)旧(6)梦(7).\n",
      "\n",
      "Line6: \"楼连天际变新城\" Count: 楼(1)连(2)天(3)际(4)变(5)新(6)城(7).\n",
      "\n",
      "Line7: \"潮起潮落留烟雾\" Count: 潮(1)起(2)潮(3)落(4)留(5)烟(6)雾(7).\n",
      "\n",
      "Line8: \"人来人往写传奇城\" Count: 人(1)来(2)人(3)往(4)写(5)传(6)奇(7)城(8). That's 8, too many. Need 7. Perhaps \"人来人往写传奇\" ends with \"传\"? Not rhyme.\n",
      "\n",
      "Could adjust to 7 characters. Example: \"人来人往写传奇\" Count: 人(1)来(2)人(3)往(4)写(5)传(6)奇(7). Ends with \"奇\", not rhyme.\n",
      "\n",
      "Alternatively \"人来人往写传说城\" Count: 人(1)来(2)人(3)往(4)写(5)传(6)说(7)城(8) too many.\n",
      "\n",
      "Maybe use \"人来人往写传奇\" ends with \"奇\", could rhyme with something else but not same as -城. Eh.\n",
      "\n",
      "We might choose a different rhyme scheme: For simplicity, we could set rhyme on lines 2,4,6,8 but we can choose any rhyme that works. For Chinese regulated poems, the rhyme is usually a character that ends with the same rhyme rhyme (-zhang?). For instance, using \"城\" is fine. We'll keep lines 6 and 8 ending with \"城\".\n",
      "\n",
      "Now lines 2,4,6,8 ended with \"城\". Line2: \"灯火通明换旧城\". OK. Line4: \"古运河里声声城\". OK. Line6: \"楼连天际变新城\". OK. Line8 need to end with \"城\" and 7 chars. Maybe: \"人来人往写传奇城\". Let's count: 人(1)来(2)人(3)往(4)写(5)传(6)奇(7)城(8). Too many. We can drop a word: \"人来人往写传奇城\". We had 8. Remove \"传奇\": \"人来人往写传城\". Count: 人(1)来(2)人(3)往(4)写(5)传(6)城(7). Good. That ends with \"城\". Could be okay, though \"传\" is \"chuán\". That might not be a typical rhyme, but \"城\" is fine. So we keep.\n",
      "\n",
      "Now ensure parallelism: Lines 3 and 4 should be parallel: line3: \"银光霓虹合眼前\" and line4: \"古运河里声声城\". Are they parallel? To enforce parallelism, both lines should have same number of characters, similar grammatical structure. line3: \"银光霓虹合眼前\" means \"silver light neon bright merges before the eyes\". line4: \"古运河里声声城\": \"Old river of commerce inside the city sounding\". Hmm.\n",
      "\n",
      "Better, we could choose symmetrical lines: For the third line, something about \"老街\", \"新建筑\". For the fourth line, \"旧巷\", \"新城\". Some typical example: \"旧城残灯照宫阙\" and \"新城熠熠映天开\" etc.\n",
      "\n",
      "Actually, better approach: Use widely used standardized structure. I've seen examples of Li Bai's regulated verse: \"闲看庭前树 ?\". But we don't need that high level.\n",
      "\n",
      "Simplify: Provide a polished poem:\n",
      "\n",
      "eight lines, each 7 chars, using natural flow. Also include parallelism in session 1. Alternative e.g.:\n",
      "\n",
      "Line1: \"海角江山映浦城\" Count: 海(1)角(2)江(3)山(4)映(5)浦(6)城(7).\n",
      "\n",
      "Line2: \"灯火通明旧港城\" Count: 灯(1)火(2)通(3)明(4)旧(5)港(6)城(7).\n",
      "\n",
      "Line3: \"楼阁多彩迎锦绣\" Count: 楼(1)阁(2)多(3)彩(4)迎(5)锦(6)绣(7). Need rhyme? maybe not.\n",
      "\n",
      "Line4: \"桥梁静叹浓烟城\" Count: 桥(1)梁(2)静(3)叹(4)浓(5)烟(6)城(7). But line4 must parallel line3: This might not be great.\n",
      "\n",
      "Let's try more structured example:\n",
      "\n",
      "Line1: \"海城光影映潮生\" – 7 char? 海(1)城(2)光(3)影(4)映(5)潮(6)生(7). Good.\n",
      "\n",
      "Line2: \"灯火通明旧港城\" – 7 char: 灯(1)火(2)通(3)明(4)旧(5)港(6)城(7). Ends rhyme? '城'.\n",
      "\n",
      "Line3: \"金浪潮声迎客船\" – 金(1)浪(2)潮(3)声(4)迎(5)客(6)船(7). But line3 and 4 parallel: line4 maybe \"银波光映青年船\"? Not good.\n",
      "\n",
      "Ok.\n",
      "\n",
      "Alternate approach: Use typical regulated structure: For 8 lines, the pattern can be considered as:\n",
      "\n",
      "First pair: lines 1-2 as a couplet with parallelism? Actually, in regulated verse: lines 1-4 and 5-8 are two couplets. Lines 1-2 should be parallel? Wait, there are two group of four lines. Within each group, lines 3-4 and 7-8 are parallel. In addition, lines 1-4 and 5-8 have certain tonal patterns. But widely known: For a quatrain of 7 words, it's a \"four-line regulated verse\". The normal structure: First two lines are couplet line 1-2, whose second lines of the two couplets are parallel? Hmm.\n",
      "\n",
      "Let's recall the structure: In a 7-character regulated verse, the second poem has two couplets: lines 1-2, lines 3-4, lines 5-6, lines 7-8. Each line has 7 characters; line 1 is neutral, line 2 rhymes. Lines 3-4 have characters 3,4,5 (?), step.\n",
      "\n",
      "But maybe we don't need to fully adhere to strict tones. Only to give a nicer poem performing regulated verse style. Ok.\n",
      "\n",
      "We can produce a poem:\n",
      "\n",
      "Line1: 海角江畔映潮城 \n",
      "Line2: 灯火通明旧港城 \n",
      "Line3: 黄浦浪涌映纸雾 \n",
      "Line4: 老巷声声与新城 \n",
      "Line5: 风帆迹迹洗旧梦 \n",
      "Line6: 珠山云影变新城 \n",
      "Line7: 潮起潮落留烟雾 \n",
      "Line8: 人来人往写传城\n",
      "\n",
      "But line8 is 8 characters? Count: 人(1)来(2)人(3)往(4)写(5)传(6)城(7). Wait we lost count? Actually line8 length:人来人往写传城: 人(1)来(2)人(3)往(4)写(5)传(6)城(7). That's 7? Wait we had \"写传城\": 写(5)传(6)城(7). So good. So line8 is \"人来人往写传城\". Good.\n",
      "\n",
      "But we had \"写传城\": but \"传\" spelled \"传\". Good.\n",
      "\n",
      "Now check rhyme: Lines 2,4,6,8 end with \"城\". They rhyme. Lines 1,3,5,7 end with \"城\"? Wait line1 ends with \"城\". Actually line1 is \"海角江畔映潮城\" ends with \"城\". That's also rhyme; but they said lines 2,4,6,8; but we have all 8 lines ending with \"城\". That's okay also.\n",
      "\n",
      "But do we have parallelism: lines 3-4: \"黄浦浪涌映纸雾\" and \"老巷声声与新城\". They are not parallel. We need to craft better pairs: lines 3-4 parallel, and lines 7-8 parallel.\n",
      "\n",
      "Also we want to convey shell. Let's try again.\n",
      "\n",
      "Let's structure:\n",
      "\n",
      "Line1: 海角风光照浦城\n",
      "Line2: 浪潮翻涌置旧城\n",
      "Line3: 金浪光芒映楼阁\n",
      "Line4: 旧巷仍闻新城\n",
      "But line3 and 4 not balanced.\n",
      "\n",
      "Ok we need clarity. Let's produce a regulated verse with proper parallelism. For that, we need to think of synonyms aligning.\n",
      "\n",
      "Suppose line3: \"金色灯光照繁华\" - 7 char: 金(1)色(2)灯(3)光(4)照(5)繁(6)华(7). \n",
      "Line4: \"旧港人潮拥新城\": 旧(1)港(2)人(3)潮(4)拥(5)新(6)城(7). But \"旧港人潮拥新城\" maybe not parallel.\n",
      "\n",
      "We want symmetrical structure: maybe something like \"古运河水映旧巷\" and \"新城灯火明楼桥\". But not symmetrical.\n",
      "\n",
      "Better to use two scenes under same idea: first the old, second the new. Eg. lines3: \"古运河潮声旧巷\" 7 char? 古(1)运(2)河(3)潮(4)声(5)旧(6)巷(7). line4: \"新桥灯火映城楼\"  新(1)桥(2)灯(3)火(4)映(5)城(6)楼(7). Good parallel: both have six? no. They are both 7. But content conj. But may not be perfect.\n",
      "\n",
      "Also lines 1-2 and 3-4 are considered punctuation. Actually, the rule: first and fourth lines are the couplet (line 2 is the parallel to line 1?), but not exactly. Usually, for regulated verses, the second (fourth) line is the one that must rhyme but does not need to be parallel to the first line. The third line of each quatrain usually goes into the parallelism. Actually I'm fuzzy.\n",
      "\n",
      "Let's search memory: In a four-line regulated verse (seven-character), the first two lines form a couplet with parallelism? Wait maybe more typical: lines 1-2 are a couplet that is harmonious, but lines 3-4 are the ones constructed as an internal couplet? Eh.\n",
      "\n",
      "Better to use guidelines:\n",
      "\n",
      "- Each line has 7 characters.\n",
      "- The rhyme: lines 2,4,6,8 must end with the same rhyme (tone).\n",
      "- Tier of tones must obey pattern (level and deflection). But we can ignore that.\n",
      "\n",
      "- Parallelism: the second half of the first couplet (lines 3-4) and the second half of the second couplet (lines 7-8) must be parallel.\n",
      "\n",
      "So for first 4 lines:\n",
      "\n",
      "Lines 1 & \n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"model\": MODEL_ID,\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": max_tokens,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "print(prompt)\n",
    "print(\"======\")\n",
    "response = sagemaker_runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.end()\n",
    "            # print(data)\n",
    "            print(data[\"choices\"][0][\"text\"], end=\"\")\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Speed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浦江潮起映金波  \n",
      "外滩灯火映夜空  \n",
      "东方明珠高耸云上天  \n",
      "旧城新貌映春秋  \n",
      "\n",
      "人潮涌动汇四海潮声  \n",
      "车水马龙映晨曦  \n",
      "文化交融谱新曲声韵悠情  \n",
      "未来之城梦永续光辉耀星光{'id': 'chatcmpl-efe8ef657d7f4786a073d0da4acc2e8d', 'object': 'chat.completion.chunk', 'created': 1758982179, 'model': 'openai/gpt-oss-20b', 'choices': [], 'usage': {'prompt_tokens': 80, 'total_tokens': 3756, 'completion_tokens': 3676}}\n",
      "\n",
      "==================================================\n",
      "Input_tokens 80 Output_tokens 3676\n",
      "First token latency 39.7 seconds\n",
      "Output speed 4.22e+03 tokens/seconds\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "sagemaker_runtime = boto3.client('runtime.sagemaker')\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"帮我写一首七言律诗介绍上海\"\n",
    "}]\n",
    "\n",
    "payload = {\n",
    "    \"model\": MODEL_ID,\n",
    "    \"messages\": messages,\n",
    "    \"max_tokens\": 4096,\n",
    "    \"temperature\": 0.0,\n",
    "    \"stream\": True,\n",
    "    \"stream_options\": {\"include_usage\": True},\n",
    "}\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "time_start = time.time()\n",
    "first_token_latency = 0\n",
    "output = []\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            chunk = json.loads(match.group(1).strip())\n",
    "            last_idx = match.span()[1]\n",
    "            # print(chunk)\n",
    "            if \"usage\" in chunk:\n",
    "                print(chunk)\n",
    "                input_tokens = chunk[\"usage\"][\"prompt_tokens\"]\n",
    "                output_tokens = chunk[\"usage\"][\"completion_tokens\"]\n",
    "            if \"choices\" in data and chunk[\"choices\"][0][\"delta\"][\"content\"]:\n",
    "                if first_token_latency == 0:\n",
    "                    first_token_latency = time.time() - time_start\n",
    "                output.append(chunk[\"choices\"][0][\"delta\"][\"content\"])\n",
    "                print(output[-1], end=\"\", flush=True)\n",
    "                \n",
    "            \n",
    "\n",
    "\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]\n",
    "\n",
    "\n",
    "total_time = time.time() - time_start\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Input_tokens\", input_tokens, \"Output_tokens\", output_tokens)\n",
    "print(f\"First token latency {first_token_latency:.3} seconds\")\n",
    "print(f\"Output speed {output_tokens/(total_time-first_token_latency):.3} tokens/seconds\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Integrate with Strands Agent SDK\n",
    "\n",
    "[Link: Custimize SageMaker model provider](https://github.com/yytdfc/strands-agent-demo/tree/main/invoke_sagemaker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clean up\n",
    "\n",
    "You could delete files using these functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_endpoint(endpoint_name):\n",
    "    try:\n",
    "        sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "        print(f\"Endpoint '{endpoint_name}' deletion initiated.\")\n",
    "\n",
    "        # Wait for the endpoint to be deleted\n",
    "        while True:\n",
    "            try:\n",
    "                sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "                print(\"Waiting for endpoint to be deleted...\")\n",
    "                time.sleep(30)\n",
    "            except sagemaker_client.exceptions.ClientError:\n",
    "                print(f\"Endpoint '{endpoint_name}' has been deleted.\")\n",
    "                break\n",
    "    except sagemaker_client.exceptions.ClientError as e:\n",
    "        print(f\"Error deleting endpoint: {e}\")\n",
    "\n",
    "def delete_endpoint_config(endpoint_config_name):\n",
    "    try:\n",
    "        sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "        print(f\"Endpoint configuration '{endpoint_config_name}' has been deleted.\")\n",
    "    except sagemaker_client.exceptions.ClientError as e:\n",
    "        print(f\"Error deleting endpoint configuration: {e}\")\n",
    "\n",
    "def delete_model(model_name):\n",
    "    try:\n",
    "        sagemaker_client.delete_model(ModelName=model_name)\n",
    "        print(f\"Model '{model_name}' has been deleted.\")\n",
    "    except sagemaker_client.exceptions.ClientError as e:\n",
    "        print(f\"Error deleting model: {e}\")\n",
    "\n",
    "        \n",
    "# delete_endpoint(endpoint_name)\n",
    "\n",
    "# delete_endpoint_config(endpoint_config_name)\n",
    "\n",
    "# delete_model(endpoint_model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
